{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTW MAM Model V1 \n",
    "# County Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current\n",
      "2020-10-02\n",
      "2020-10-15\n",
      "2020-10-15\n",
      "2020-10-09\n",
      "2020-10-08\n",
      "2020-10-02\n",
      "3 day\n",
      "2020-09-29\n",
      "2020-10-12\n",
      "2020-10-12\n",
      "2020-10-06\n",
      "2020-10-05\n",
      "2020-09-29\n",
      "7 day\n",
      "2020-09-25\n",
      "2020-10-08\n",
      "2020-10-08\n",
      "2020-10-02\n",
      "2020-10-01\n",
      "2020-09-25\n",
      "14 day\n",
      "2020-09-18\n",
      "2020-10-01\n",
      "2020-10-01\n",
      "2020-09-25\n",
      "2020-09-24\n",
      "2020-09-18\n"
     ]
    }
   ],
   "source": [
    "#SET DATE FILTERS & FileName\n",
    "today = date.today()\n",
    "yesterday = today - timedelta(days=1)\n",
    "yesterday = yesterday.strftime('_%Y%m%d')\n",
    "\n",
    "file = 'CountyMAM2_'+yesterday+'_.csv'\n",
    "state_file = 'State_MAM2_'+yesterday+'_.csv'\n",
    "\n",
    "\n",
    "preval_end = datetime.today()- timedelta(days=1)\n",
    "preval_end = datetime.strftime(preval_end,'%Y-%m-%d')\n",
    "\n",
    "preval_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=13)\n",
    "preval_start = preval_start.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=6)\n",
    "curr_start = curr_start.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end = datetime.strptime(preval_end,'%Y-%m-%d')\n",
    "curr_end = curr_end.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=13)\n",
    "prev_start = prev_start.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=7)\n",
    "prev_end = prev_end.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "#Add 3 more for 3 day look back, 7 day, 14 day##\n",
    "##3 DAY HISTORICAL LOOK BACK##\n",
    "\n",
    "preval_start_3 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_start_3 = preval_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_3 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_end_3 = preval_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_3 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_start_3 = curr_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_3 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_end_3 = curr_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_3 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_start_3 = prev_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_3 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_end_3 = prev_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##7 DAY HISTORICAL LOOK BACK##\n",
    "preval_start_7 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_start_7 = preval_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_7 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_end_7 = preval_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_7 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_start_7 = curr_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_7 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_end_7 = curr_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_7 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_start_7 = prev_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_7 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_end_7 = prev_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##14 HISTORICAL DAY LOOK BACK##\n",
    "preval_start_14 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_start_14 = preval_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_14 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_end_14 = preval_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_14 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_start_14 = curr_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_14 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_end_14 = curr_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_14 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_start_14 = prev_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_14 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_end_14 = prev_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"Current\")\n",
    "print(preval_start)\n",
    "print(preval_end)\n",
    "\n",
    "print(curr_end)\n",
    "print(curr_start)\n",
    "print(prev_end)\n",
    "print(prev_start)\n",
    "\n",
    "\n",
    "print(\"3 day\")\n",
    "print(preval_start_3)\n",
    "print(preval_end_3)\n",
    "\n",
    "print(curr_end_3)\n",
    "print(curr_start_3)\n",
    "print(prev_end_3)\n",
    "print(prev_start_3)\n",
    "\n",
    "print(\"7 day\")\n",
    "print(preval_start_7)\n",
    "print(preval_end_7)\n",
    "\n",
    "print(curr_end_7)\n",
    "print(curr_start_7)\n",
    "print(prev_end_7)\n",
    "print(prev_start_7)\n",
    "\n",
    "print(\"14 day\")\n",
    "print(preval_start_14)\n",
    "print(preval_end_14)\n",
    "\n",
    "print(curr_end_14)\n",
    "print(curr_start_14)\n",
    "print(prev_end_14)\n",
    "print(prev_start_14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201015\n",
      "20201009\n",
      "20201008\n",
      "20201002\n",
      "20201012\n",
      "20201006\n",
      "20201005\n",
      "20200929\n",
      "20201008\n",
      "20201002\n",
      "20201001\n",
      "20200925\n",
      "20201001\n",
      "20200925\n",
      "20200924\n",
      "20200918\n"
     ]
    }
   ],
   "source": [
    "curr_test_start = int(curr_end.replace('-',''))\n",
    "curr_test_end = int(curr_start.replace('-',''))\n",
    "prev_test_start = int(prev_end.replace('-',''))\n",
    "prev_test_end = int(prev_start.replace('-',''))\n",
    "\n",
    "##3 day look back##\n",
    "\n",
    "curr_test_start_3 = int(curr_end_3.replace('-',''))\n",
    "curr_test_end_3 = int(curr_start_3.replace('-',''))\n",
    "prev_test_start_3 = int(prev_end_3.replace('-',''))\n",
    "prev_test_end_3 = int(prev_start_3.replace('-',''))\n",
    "\n",
    "##7day look back##\n",
    "curr_test_start_7 =int(curr_end_7.replace('-',''))\n",
    "curr_test_end_7 = int(curr_start_7.replace('-',''))\n",
    "prev_test_start_7 = int(prev_end_7.replace('-',''))\n",
    "prev_test_end_7 = int(prev_start_7.replace('-',''))\n",
    "\n",
    "##14 day look back##\n",
    "curr_test_start_14 = int(curr_end_14.replace('-',''))\n",
    "curr_test_end_14 = int(curr_start_14.replace('-',''))\n",
    "prev_test_start_14 = int(prev_end_14.replace('-',''))\n",
    "prev_test_end_14 = int(prev_start_14.replace('-',''))\n",
    "\n",
    "print(curr_test_start)\n",
    "print(curr_test_end)\n",
    "print(prev_test_start)\n",
    "print(prev_test_end)\n",
    "\n",
    "print(curr_test_start_3)\n",
    "print(curr_test_end_3)\n",
    "print(prev_test_start_3)\n",
    "print(prev_test_end_3)\n",
    "\n",
    "print(curr_test_start_7)\n",
    "print(curr_test_end_7)\n",
    "print(prev_test_start_7)\n",
    "print(prev_test_end_7)\n",
    "\n",
    "print(curr_test_start_14)\n",
    "print(curr_test_end_14)\n",
    "print(prev_test_start_14)\n",
    "print(prev_test_end_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATES NEEDED - bring in base file, within base file add in state 2 digit codes\n",
    "#Need to add in the NYC FIPS dummy code\n",
    "\n",
    "#Bring in County Data set\n",
    "nytimes = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "counties = pd.read_csv(nytimes,dtype={'fips': str})\n",
    "\n",
    "\n",
    "\n",
    "base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/base_rtw_v2.csv\"\n",
    "pop_df = pd.read_csv(base,\n",
    "                dtype={'fips': str})\n",
    "\n",
    "state_base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/state_base_v1.csv\"\n",
    "state_pop_df = pd.read_csv(state_base)\n",
    "#pop_df = pd.read_csv(\"base_rtw_v1.csv\",\n",
    "#                dtype={'fips': str})\n",
    "\n",
    "#base['fips2'] = np.where(base['county']=='New York City','36061',base['fips'])\n",
    "\n",
    "counties.loc[counties['county'] == 'New York City', 'fips'] = '36061'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Active Case Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date   county    state   fips  cases  deaths\n",
      "9480   2020-03-24  Autauga  Alabama  01001      1       0\n",
      "10835  2020-03-25  Autauga  Alabama  01001      4       0\n",
      "12367  2020-03-26  Autauga  Alabama  01001      6       0\n",
      "14025  2020-03-27  Autauga  Alabama  01001      6       0\n",
      "15803  2020-03-28  Autauga  Alabama  01001      6       0\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "counties.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(counties.head())\n",
    "# counties.to_csv(\"Counties.csv\")\n",
    "#Take difference between rows for new case and new death numbers\n",
    "counties['case_diff'] = counties.cases.diff()\n",
    "counties['death_diff'] = counties.deaths.diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for past 14 days\n",
    "#range_14 = counties[counties['date']>=preval_start]\n",
    "\n",
    "range_14 = counties[(counties['date']>=preval_start) & (counties['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = counties[(counties['date']>=preval_start_3) & (counties['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = counties[(counties['date']>=preval_start_7) & (counties['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = counties[(counties['date']>=preval_start_14) & (counties['date']<=preval_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by FIPS, sum up new Cases for prevalence - for 7 day averages will take mean after filtering for 7 days\n",
    "prevalence_grouped = range_14.groupby(['fips'], as_index=False).sum()\n",
    "\n",
    "#3 day#\n",
    "prevalence_grouped_3 = range_14_3.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_3[\"case_diff_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "prevalence_grouped_7 = range_14_7.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_7[\"case_diff_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "prevalence_grouped_14 = range_14_14.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_14[\"case_diff_14\"] = prevalence_grouped_14[\"case_diff\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join in Prevalence to \n",
    "prevalence_w_pop_a = pd.merge(pop_df,\n",
    "                 prevalence_grouped[['fips','case_diff']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_b = pd.merge(prevalence_w_pop_a,\n",
    "                 prevalence_grouped_3[['fips','case_diff_3']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_c = pd.merge(prevalence_w_pop_b,\n",
    "                 prevalence_grouped_7[['fips','case_diff_7']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "prevalence_w_pop = pd.merge(prevalence_w_pop_c,\n",
    "                 prevalence_grouped_14[['fips','case_diff_14']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_pop Homeloc_count_CCC  \\\n",
      "0   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "1   1.0          13.0                3.0  ...    4908621             102.0   \n",
      "2  61.0           6.0                5.0  ...    4908621             154.0   \n",
      "3   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "4   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "\n",
      "  case_diff case_diff_3 case_diff_7  case_diff_14  active_cases_100k  \\\n",
      "0    1589.0      1683.0      1524.0        1660.0         241.279251   \n",
      "1     501.0       512.0       558.0         670.0         121.245856   \n",
      "2     686.0       627.0       621.0         691.0         183.959089   \n",
      "3     535.0       428.0       329.0         358.0         236.217691   \n",
      "4     288.0       632.0       976.0         976.0         129.012606   \n",
      "\n",
      "   active_cases_100k_3day  active_cases_100k_7day  active_cases_100k_14day  \n",
      "0              255.552536              231.409426               252.060136  \n",
      "1              123.907940              135.040294               162.145156  \n",
      "2              168.137535              166.528563               185.299899  \n",
      "3              188.974153              145.262842               158.067165  \n",
      "4              283.110996              437.209386               437.209386  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "prevalence_w_pop['active_cases_100k'] = ((prevalence_w_pop['case_diff']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_3day'] = ((prevalence_w_pop['case_diff_3']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_7day'] = ((prevalence_w_pop['case_diff_7']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_14day'] = ((prevalence_w_pop['case_diff_14']/prevalence_w_pop['pop'])*100000)\n",
    "print(prevalence_w_pop.head())\n",
    "# prevalence_w_pop.to_csv('mamnum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 7 Day Rolling Avgs for Cases & Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Diff datasets for current and previous 7 day periods\n",
    "\n",
    "#join prev and current together with pop\n",
    "\n",
    "range_current7 = counties[(counties['date']>=curr_start) & (counties['date']<=curr_end)]\n",
    "range_prev7 = counties[(counties['date']>=prev_start) & (counties['date']<=prev_end)]\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "range_current7_3 = counties[(counties['date']>=curr_start_3) & (counties['date']<=curr_end_3)]\n",
    "range_prev7_3 = counties[(counties['date']>=prev_start_3) & (counties['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "range_current7_7 = counties[(counties['date']>=curr_start_7) & (counties['date']<=curr_end_7)]\n",
    "range_prev7_7 = counties[(counties['date']>=prev_start_7) & (counties['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "range_current7_14 = counties[(counties['date']>=curr_start_14) & (counties['date']<=curr_end_14)]\n",
    "range_prev7_14 = counties[(counties['date']>=prev_start_14) & (counties['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by with mean\n",
    "current_grouped = range_current7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped = range_prev7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped['curr7_case'] = current_grouped['case_diff']\n",
    "current_grouped['curr7_death'] = current_grouped['death_diff']\n",
    "previous_grouped['prev7_case'] = previous_grouped['case_diff']\n",
    "previous_grouped['prev7_death'] = previous_grouped['death_diff']\n",
    "current_grouped['Under 50 New Cases Flag'] = np.where(current_grouped['curr7_case'] < 50, \"Y\", \"\")\n",
    "\n",
    "#3 day look back#\n",
    "current_grouped_3 = range_current7_3.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_3 = range_prev7_3.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_3['curr7_case_3day'] = current_grouped_3['case_diff']\n",
    "current_grouped_3['curr7_death_3day'] = current_grouped_3['death_diff']\n",
    "previous_grouped_3['prev7_case_3day'] = previous_grouped_3['case_diff']\n",
    "previous_grouped_3['prev7_death_3day'] = previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "current_grouped_7 = range_current7_7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_7 = range_prev7_7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_7['curr7_case_7day'] = current_grouped_7['case_diff']\n",
    "current_grouped_7['curr7_death_7day'] = current_grouped_7['death_diff']\n",
    "previous_grouped_7['prev7_case_7day'] = previous_grouped_7['case_diff']\n",
    "previous_grouped_7['prev7_death_7day'] = previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "current_grouped_14 = range_current7_14.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_14 = range_prev7_14.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_14['curr7_case_14day'] = current_grouped_14['case_diff']\n",
    "current_grouped_14['curr7_death_14day'] = current_grouped_14['death_diff']\n",
    "previous_grouped_14['prev7_case_14day'] = previous_grouped_14['case_diff']\n",
    "previous_grouped_14['prev7_death_14day'] = previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "5  01117      Shelby  Alabama         AL      NaN   3.0                0.0   \n",
      "6  01125  Tuscaloosa  Alabama         AL      NaN   1.0               34.0   \n",
      "7  01081         Lee  Alabama         AL      NaN   2.0                0.0   \n",
      "8  01103      Morgan  Alabama         AL      NaN   0.0                0.0   \n",
      "9  01015     Calhoun  Alabama         AL      NaN   5.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  Homeloc_count_CCC  curr7_case  \\\n",
      "0   0.0           0.0                0.0  ...                0.0  133.142857   \n",
      "1   1.0          13.0                3.0  ...              102.0   41.571429   \n",
      "2  61.0           6.0                5.0  ...              154.0   52.428571   \n",
      "3   0.0           0.0                0.0  ...                0.0   49.428571   \n",
      "4   0.0           0.0                0.0  ...                0.0   20.571429   \n",
      "5   0.0           0.0                0.0  ...                0.0   50.857143   \n",
      "6   3.0           8.0                0.0  ...               55.0   48.285714   \n",
      "7   0.0           0.0                0.0  ...                0.0   17.714286   \n",
      "8   0.0           0.0                0.0  ...                0.0   35.571429   \n",
      "9   0.0           0.0                0.0  ...                0.0   28.142857   \n",
      "\n",
      "  curr7_death Under 50 New Cases Flag curr7_case_3day  curr7_death_3day  \\\n",
      "0    0.714286                              112.142857          1.142857   \n",
      "1    0.714286                       Y       34.142857          1.714286   \n",
      "2    0.714286                               47.000000          0.714286   \n",
      "3    1.000000                       Y       37.714286          0.428571   \n",
      "4    0.285714                       Y       19.285714          1.714286   \n",
      "5    0.571429                               42.714286          1.000000   \n",
      "6    0.857143                       Y       46.857143          1.285714   \n",
      "7    0.285714                       Y       24.142857          0.428571   \n",
      "8   -0.142857                       Y       30.000000          0.142857   \n",
      "9    2.000000                       Y       22.285714          0.714286   \n",
      "\n",
      "   curr7_case_7day  curr7_death_7day  curr7_case_14day  curr7_death_14day  \n",
      "0        93.857143          0.714286        123.857143           0.714286  \n",
      "1        30.000000          1.857143         49.714286           0.571429  \n",
      "2        45.571429          0.714286         43.142857          -0.285714  \n",
      "3        27.000000          0.142857         20.000000           1.142857  \n",
      "4        20.571429          1.571429        118.857143           0.428571  \n",
      "5        39.428571          0.857143         53.142857          -0.142857  \n",
      "6        46.285714          0.857143        220.571429          -0.142857  \n",
      "7        28.571429          0.428571         30.571429           0.000000  \n",
      "8        27.000000          0.571429         15.428571           0.142857  \n",
      "9        23.571429          0.142857         17.285714           0.428571  \n",
      "\n",
      "[10 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Current with population\n",
    "current_w_pop_a = pd.merge(pop_df,\n",
    "                 current_grouped[['fips','curr7_case', 'curr7_death','Under 50 New Cases Flag']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "current_w_pop_b = pd.merge(current_w_pop_a,\n",
    "                 current_grouped_3[['fips','curr7_case_3day', 'curr7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop_c = pd.merge(current_w_pop_b,\n",
    "                 current_grouped_7[['fips','curr7_case_7day', 'curr7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop = pd.merge(current_w_pop_c,\n",
    "                 current_grouped_14[['fips','curr7_case_14day', 'curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(current_w_pop.head(10))\n",
    "\n",
    "# current_w_pop.to_csv(\"Less50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "5  01117      Shelby  Alabama         AL      NaN   3.0                0.0   \n",
      "6  01125  Tuscaloosa  Alabama         AL      NaN   1.0               34.0   \n",
      "7  01081         Lee  Alabama         AL      NaN   2.0                0.0   \n",
      "8  01103      Morgan  Alabama         AL      NaN   0.0                0.0   \n",
      "9  01015     Calhoun  Alabama         AL      NaN   5.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_pop Homeloc_count_CCC  \\\n",
      "0   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "1   1.0          13.0                3.0  ...    4908621             102.0   \n",
      "2  61.0           6.0                5.0  ...    4908621             154.0   \n",
      "3   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "4   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "5   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "6   3.0           8.0                0.0  ...    4908621              55.0   \n",
      "7   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "8   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "9   0.0           0.0                0.0  ...    4908621               0.0   \n",
      "\n",
      "  prev7_case prev7_death prev7_case_3day  prev7_death_3day  prev7_case_7day  \\\n",
      "0  93.857143    0.714286      128.285714          0.571429       123.857143   \n",
      "1  30.000000    1.857143       39.000000          0.714286        49.714286   \n",
      "2  45.571429    0.714286       42.571429          0.000000        43.142857   \n",
      "3  27.000000    0.142857       23.428571          0.285714        20.000000   \n",
      "4  20.571429    1.571429       71.000000          0.428571       118.857143   \n",
      "5  39.428571    0.857143       52.000000          0.285714        53.142857   \n",
      "6  46.285714    0.857143       67.857143          0.142857       220.571429   \n",
      "7  28.571429    0.428571       30.142857          0.142857        30.571429   \n",
      "8  27.000000    0.571429       22.000000          0.428571        15.428571   \n",
      "9  23.571429    0.142857       22.428571          0.000000        17.285714   \n",
      "\n",
      "   prev7_death_7day  prev7_case_14day  prev7_death_14day  \n",
      "0          0.714286        113.285714           2.428571  \n",
      "1          0.571429         46.000000           0.428571  \n",
      "2         -0.285714         55.571429           1.000000  \n",
      "3          1.142857         31.142857           1.285714  \n",
      "4          0.428571         20.571429           0.285714  \n",
      "5         -0.142857         49.714286           0.285714  \n",
      "6         -0.142857         68.714286           1.000000  \n",
      "7          0.000000         35.285714           0.285714  \n",
      "8          0.142857         17.857143           0.428571  \n",
      "9          0.428571         36.428571           0.285714  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Previous with population\n",
    "\n",
    "previous_w_pop_a = pd.merge(pop_df,\n",
    "                 previous_grouped[['fips','prev7_case', 'prev7_death']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_b = pd.merge(previous_w_pop_a,\n",
    "                 previous_grouped_3[['fips','prev7_case_3day', 'prev7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_c = pd.merge(previous_w_pop_b,\n",
    "                 previous_grouped_7[['fips','prev7_case_7day', 'prev7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop = pd.merge(previous_w_pop_c,\n",
    "                 previous_grouped_14[['fips','prev7_case_14day', 'prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(previous_w_pop.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_w_pop['cur_7rollavg_cases'] = ((current_w_pop['curr7_case']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths'] = ((current_w_pop['curr7_death']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#3 day#\n",
    "current_w_pop['cur_7rollavg_cases_3day'] = ((current_w_pop['curr7_case_3day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_3day'] = ((current_w_pop['curr7_death_3day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "current_w_pop['cur_7rollavg_cases_7day'] = ((current_w_pop['curr7_case_7day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_7day'] = ((current_w_pop['curr7_death_7day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "current_w_pop['cur_7rollavg_cases_14day'] = ((current_w_pop['curr7_case_14day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_14day'] = ((current_w_pop['curr7_death_14day']/current_w_pop['pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_w_pop['prev_7rollavg_cases'] = ((previous_w_pop['prev7_case']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths'] = ((previous_w_pop['prev7_death']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#3day#\n",
    "previous_w_pop['prev_7rollavg_cases_3day'] = ((previous_w_pop['prev7_case_3day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_3day'] = ((previous_w_pop['prev7_death_3day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "previous_w_pop['prev_7rollavg_cases_7day'] = ((previous_w_pop['prev7_case_7day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_7day'] = ((previous_w_pop['prev7_death_7day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "previous_w_pop['prev_7rollavg_cases_14day'] = ((previous_w_pop['prev7_case_14day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_14day'] = ((previous_w_pop['prev7_death_14day']/previous_w_pop['pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with prevalence dataset\n",
    "prev_curr = pd.merge(prevalence_w_pop,\n",
    "                 current_w_pop[['fips','Under 50 New Cases Flag','curr7_case','cur_7rollavg_cases', 'cur_7rollavg_deaths','curr7_death',\n",
    "                               'cur_7rollavg_cases_3day', 'cur_7rollavg_deaths_3day','curr7_case_3day','curr7_death_3day',\n",
    "                               'cur_7rollavg_cases_7day', 'cur_7rollavg_deaths_7day','curr7_case_7day','curr7_death_7day',\n",
    "                                'cur_7rollavg_cases_14day', 'cur_7rollavg_deaths_14day','curr7_case_14day','curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_set = pd.merge(prev_curr,\n",
    "                 previous_w_pop[['fips','prev_7rollavg_cases', 'prev_7rollavg_deaths','prev7_case','prev7_death',\n",
    "                                'prev_7rollavg_cases_3day', 'prev_7rollavg_deaths_3day','prev7_case_3day','prev7_death_3day',\n",
    "                               'prev_7rollavg_cases_7day', 'prev_7rollavg_deaths_7day','prev7_case_7day','prev7_death_7day',\n",
    "                                'prev_7rollavg_cases_14day', 'prev_7rollavg_deaths_14day','prev7_case_14day','prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  prev7_case_14day  \\\n",
      "0   0.0           0.0                0.0  ...        113.285714   \n",
      "1   1.0          13.0                3.0  ...         46.000000   \n",
      "2  61.0           6.0                5.0  ...         55.571429   \n",
      "3   0.0           0.0                0.0  ...         31.142857   \n",
      "4   0.0           0.0                0.0  ...         20.571429   \n",
      "\n",
      "  prev7_death_14day roll7case_diff roll7death_diff roll7case_diff_3day  \\\n",
      "0          2.428571       0.418569        0.000000           -0.125835   \n",
      "1          0.428571       0.385714       -0.615385           -0.124542   \n",
      "2          1.000000       0.150470        0.000000            0.104027   \n",
      "3          1.285714       0.830688        6.000000            0.609756   \n",
      "4          0.285714       0.000000       -0.818182           -0.728370   \n",
      "\n",
      "   roll7death_diff_3day  roll7case_diff_7day  roll7death_diff_7day  \\\n",
      "0                   1.0            -0.242215              0.000000   \n",
      "1                   1.4            -0.396552              2.250000   \n",
      "2                   inf             0.056291             -3.500000   \n",
      "3                   0.5             0.350000             -0.875000   \n",
      "4                   3.0            -0.826923              2.666667   \n",
      "\n",
      "   roll7case_diff_14day  roll7death_diff_14day  \n",
      "0              0.093317              -0.705882  \n",
      "1              0.080745               0.333333  \n",
      "2             -0.223650              -1.285714  \n",
      "3             -0.357798              -0.111111  \n",
      "4              4.777778               0.500000  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create indicators for rolling averages\n",
    "county_set['roll7case_diff'] = ((county_set['cur_7rollavg_cases']-county_set['prev_7rollavg_cases'])/county_set['prev_7rollavg_cases'])\n",
    "county_set['roll7death_diff'] = ((county_set['cur_7rollavg_deaths']-county_set['prev_7rollavg_deaths'])/county_set['prev_7rollavg_deaths'])\n",
    "\n",
    "\n",
    "#3 day#\n",
    "county_set['roll7case_diff_3day'] = ((county_set['cur_7rollavg_cases_3day']-county_set['prev_7rollavg_cases_3day'])/county_set['prev_7rollavg_cases_3day'])\n",
    "county_set['roll7death_diff_3day'] = ((county_set['cur_7rollavg_deaths_3day']-county_set['prev_7rollavg_deaths_3day'])/county_set['prev_7rollavg_deaths_3day'])\n",
    "\n",
    "\n",
    "#7day#\n",
    "county_set['roll7case_diff_7day'] = ((county_set['cur_7rollavg_cases_7day']-county_set['prev_7rollavg_cases_7day'])/county_set['prev_7rollavg_cases_7day'])\n",
    "county_set['roll7death_diff_7day'] = ((county_set['cur_7rollavg_deaths_7day']-county_set['prev_7rollavg_deaths_7day'])/county_set['prev_7rollavg_deaths_7day'])\n",
    "\n",
    "\n",
    "#14 day#\n",
    "county_set['roll7case_diff_14day'] = ((county_set['cur_7rollavg_cases_14day']-county_set['prev_7rollavg_cases_14day'])/county_set['prev_7rollavg_cases_14day'])\n",
    "county_set['roll7death_diff_14day'] = ((county_set['cur_7rollavg_deaths_14day']-county_set['prev_7rollavg_deaths_14day'])/county_set['prev_7rollavg_deaths_14day'])\n",
    "\n",
    "print(county_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in NYTimes state data, diff, do same 7 day rolling avg counts\n",
    "# pull in COVID tracking test data. calculate pos % then rolling avgs\n",
    "# Manually pull in Rt, might drop this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in state level NYT Data\n",
    "nytimes_state = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\"\n",
    "state= pd.read_csv(nytimes_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    state  fips  cases  deaths    State\n",
      "586  2020-03-13  Alabama     1      6       0  Alabama\n",
      "637  2020-03-14  Alabama     1     12       0  Alabama\n",
      "689  2020-03-15  Alabama     1     23       0  Alabama\n",
      "742  2020-03-16  Alabama     1     29       0  Alabama\n",
      "795  2020-03-17  Alabama     1     39       0  Alabama\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "state['State'] = state['state']\n",
    "state.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(state.head())\n",
    "\n",
    "#Take difference between rows for new case and new death numbers\n",
    "state['case_diff'] = state.cases.diff()\n",
    "state['death_diff'] = state.deaths.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE State Prevalence measure\n",
    "#Filter for past 14 days\n",
    "\n",
    "state_range_14 = state[(state['date']>=preval_start) & (state['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = state[(state['date']>=preval_start_3) & (state['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = state[(state['date']>=preval_start_7) & (state['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = state[(state['date']>=preval_start_14) & (state['date']<=preval_end_14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create state group for prevalence\n",
    "\n",
    "state_prevalence_grouped = state_range_14.groupby(['State'], as_index=False).sum()\n",
    "\n",
    "state_prevalence_grouped['state_active'] = state_prevalence_grouped['case_diff']\n",
    "\n",
    "\n",
    "#3 day#\n",
    "state_prevalence_grouped_3 = range_14_3.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_3[\"state_active_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "state_prevalence_grouped_7 = range_14_7.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_7[\"state_active_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "state_prevalence_grouped_14 = range_14_14.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_14[\"state_active_14\"] = prevalence_grouped_14[\"case_diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take Current and previous rolling averages\n",
    "\n",
    "state_range_current7 = state[(state['date']>=curr_start) & (state['date']<=curr_end)]\n",
    "state_range_prev7 = state[(state['date']>=prev_start) & (state['date']<=prev_end)]\n",
    "\n",
    "#3 day look back#\n",
    "state_range_current7_3 = state[(state['date']>=curr_start_3) & (state['date']<=curr_end_3)]\n",
    "state_range_prev7_3 = state[(state['date']>=prev_start_3) & (state['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_range_current7_7 = state[(state['date']>=curr_start_7) & (state['date']<=curr_end_7)]\n",
    "state_range_prev7_7 = state[(state['date']>=prev_start_7) & (state['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_range_current7_14 = state[(state['date']>=curr_start_14) & (state['date']<=curr_end_14)]\n",
    "state_range_prev7_14 = state[(state['date']>=prev_start_14) & (state['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Means\n",
    "#Group by with mean\n",
    "state_current_grouped = state_range_current7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped = state_range_prev7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped['state_curr7_case'] = state_current_grouped['case_diff']\n",
    "state_previous_grouped['state_prev7_case'] = state_previous_grouped['case_diff']\n",
    "state_current_grouped['state_curr7_death'] = state_current_grouped['death_diff']\n",
    "state_previous_grouped['state_prev7_death'] = state_previous_grouped['death_diff']\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "state_current_grouped_3 = state_range_current7_3.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_3 = state_range_prev7_3.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_3['state_curr7_case_3day'] = state_current_grouped_3['case_diff']\n",
    "state_current_grouped_3['state_curr7_death_3day'] = state_current_grouped_3['death_diff']\n",
    "state_previous_grouped_3['state_prev7_case_3day'] = state_previous_grouped_3['case_diff']\n",
    "state_previous_grouped_3['state_prev7_death_3day'] = state_previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_current_grouped_7 = state_range_current7_7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_7 = state_range_prev7_7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_7['state_curr7_case_7day'] = state_current_grouped_7['case_diff']\n",
    "state_current_grouped_7['state_curr7_death_7day'] = state_current_grouped_7['death_diff']\n",
    "state_previous_grouped_7['state_prev7_case_7day'] = state_previous_grouped_7['case_diff']\n",
    "state_previous_grouped_7['state_prev7_death_7day'] = state_previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_current_grouped_14 = state_range_current7_14.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_14 = state_range_prev7_14.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_14['state_curr7_case_14day'] = state_current_grouped_14['case_diff']\n",
    "state_current_grouped_14['state_curr7_death_14day'] = state_current_grouped_14['death_diff']\n",
    "state_previous_grouped_14['state_prev7_case_14day'] = state_previous_grouped_14['case_diff']\n",
    "state_previous_grouped_14['state_prev7_death_14day'] = state_previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "5  01117      Shelby  Alabama         AL      NaN   3.0                0.0   \n",
      "6  01125  Tuscaloosa  Alabama         AL      NaN   1.0               34.0   \n",
      "7  01081         Lee  Alabama         AL      NaN   2.0                0.0   \n",
      "8  01103      Morgan  Alabama         AL      NaN   0.0                0.0   \n",
      "9  01015     Calhoun  Alabama         AL      NaN   5.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  roll7case_diff_3day  \\\n",
      "0   0.0           0.0                0.0  ...            -0.125835   \n",
      "1   1.0          13.0                3.0  ...            -0.124542   \n",
      "2  61.0           6.0                5.0  ...             0.104027   \n",
      "3   0.0           0.0                0.0  ...             0.609756   \n",
      "4   0.0           0.0                0.0  ...            -0.728370   \n",
      "5   0.0           0.0                0.0  ...            -0.178571   \n",
      "6   3.0           8.0                0.0  ...            -0.309474   \n",
      "7   0.0           0.0                0.0  ...            -0.199052   \n",
      "8   0.0           0.0                0.0  ...             0.363636   \n",
      "9   0.0           0.0                0.0  ...            -0.006369   \n",
      "\n",
      "  roll7death_diff_3day roll7case_diff_7day roll7death_diff_7day  \\\n",
      "0             1.000000           -0.242215             0.000000   \n",
      "1             1.400000           -0.396552             2.250000   \n",
      "2                  inf            0.056291            -3.500000   \n",
      "3             0.500000            0.350000            -0.875000   \n",
      "4             3.000000           -0.826923             2.666667   \n",
      "5             2.500000           -0.258065            -7.000000   \n",
      "6             8.000000           -0.790155            -7.000000   \n",
      "7             2.000000           -0.065421                  inf   \n",
      "8            -0.666667            0.750000             3.000000   \n",
      "9                  inf            0.363636            -0.666667   \n",
      "\n",
      "  roll7case_diff_14day  roll7death_diff_14day  state_active  state_active_3  \\\n",
      "0             0.093317              -0.705882       13418.0           126.0   \n",
      "1             0.080745               0.333333       13418.0           126.0   \n",
      "2            -0.223650              -1.285714       13418.0           126.0   \n",
      "3            -0.357798              -0.111111       13418.0           126.0   \n",
      "4             4.777778               0.500000       13418.0           126.0   \n",
      "5             0.068966              -1.500000       13418.0           126.0   \n",
      "6             2.209979              -1.142857       13418.0           126.0   \n",
      "7            -0.133603              -1.000000       13418.0           126.0   \n",
      "8            -0.136000              -0.666667       13418.0           126.0   \n",
      "9            -0.525490               0.500000       13418.0           126.0   \n",
      "\n",
      "   state_active_7  state_active_14  \n",
      "0           125.0            174.0  \n",
      "1           125.0            174.0  \n",
      "2           125.0            174.0  \n",
      "3           125.0            174.0  \n",
      "4           125.0            174.0  \n",
      "5           125.0            174.0  \n",
      "6           125.0            174.0  \n",
      "7           125.0            174.0  \n",
      "8           125.0            174.0  \n",
      "9           125.0            174.0  \n",
      "\n",
      "[10 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge PREVALENCE sets with base file\n",
    "\n",
    "state_active_a= pd.merge(county_set,\n",
    "                 state_prevalence_grouped[['State','state_active']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_b = pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "state_active_c = pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active = pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(state_active.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "5  01117      Shelby  Alabama         AL      NaN   3.0                0.0   \n",
      "6  01125  Tuscaloosa  Alabama         AL      NaN   1.0               34.0   \n",
      "7  01081         Lee  Alabama         AL      NaN   2.0                0.0   \n",
      "8  01103      Morgan  Alabama         AL      NaN   0.0                0.0   \n",
      "9  01015     Calhoun  Alabama         AL      NaN   5.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_curr7_case_14day  \\\n",
      "0   0.0           0.0                0.0  ...             1076.857143   \n",
      "1   1.0          13.0                3.0  ...             1076.857143   \n",
      "2  61.0           6.0                5.0  ...             1076.857143   \n",
      "3   0.0           0.0                0.0  ...             1076.857143   \n",
      "4   0.0           0.0                0.0  ...             1076.857143   \n",
      "5   0.0           0.0                0.0  ...             1076.857143   \n",
      "6   3.0           8.0                0.0  ...             1076.857143   \n",
      "7   0.0           0.0                0.0  ...             1076.857143   \n",
      "8   0.0           0.0                0.0  ...             1076.857143   \n",
      "9   0.0           0.0                0.0  ...             1076.857143   \n",
      "\n",
      "  state_curr7_death_14day state_prev7_case state_prev7_death  \\\n",
      "0                     6.0       890.142857         12.714286   \n",
      "1                     6.0       890.142857         12.714286   \n",
      "2                     6.0       890.142857         12.714286   \n",
      "3                     6.0       890.142857         12.714286   \n",
      "4                     6.0       890.142857         12.714286   \n",
      "5                     6.0       890.142857         12.714286   \n",
      "6                     6.0       890.142857         12.714286   \n",
      "7                     6.0       890.142857         12.714286   \n",
      "8                     6.0       890.142857         12.714286   \n",
      "9                     6.0       890.142857         12.714286   \n",
      "\n",
      "  state_prev7_case_3day  state_prev7_death_3day  state_prev7_case_7day  \\\n",
      "0            961.428571                8.285714            1076.857143   \n",
      "1            961.428571                8.285714            1076.857143   \n",
      "2            961.428571                8.285714            1076.857143   \n",
      "3            961.428571                8.285714            1076.857143   \n",
      "4            961.428571                8.285714            1076.857143   \n",
      "5            961.428571                8.285714            1076.857143   \n",
      "6            961.428571                8.285714            1076.857143   \n",
      "7            961.428571                8.285714            1076.857143   \n",
      "8            961.428571                8.285714            1076.857143   \n",
      "9            961.428571                8.285714            1076.857143   \n",
      "\n",
      "   state_prev7_death_7day  state_prev7_case_14day  state_prev7_death_14day  \n",
      "0                     6.0              921.285714                     15.0  \n",
      "1                     6.0              921.285714                     15.0  \n",
      "2                     6.0              921.285714                     15.0  \n",
      "3                     6.0              921.285714                     15.0  \n",
      "4                     6.0              921.285714                     15.0  \n",
      "5                     6.0              921.285714                     15.0  \n",
      "6                     6.0              921.285714                     15.0  \n",
      "7                     6.0              921.285714                     15.0  \n",
      "8                     6.0              921.285714                     15.0  \n",
      "9                     6.0              921.285714                     15.0  \n",
      "\n",
      "[10 rows x 87 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge CURR sets with base file\n",
    "\n",
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day','state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day','state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day', 'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "\n",
    "# print(state_current_w_pop.head(10))\n",
    "\n",
    "\n",
    "county_state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_b = pd.merge(county_state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_c = pd.merge(county_state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df = pd.merge(county_state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(county_state_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create state rolling avg indicator\n",
    "#####NEED TO ADD IN STATE POP to create per 100k \n",
    "\n",
    "county_state_df['state_curr7_case100k'] = ((county_state_df['state_curr7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k'] = ((county_state_df['state_curr7_death']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k'] = ((county_state_df['state_prev7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k'] = ((county_state_df['state_prev7_death']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_curr7_case100k_3day'] = ((county_state_df['state_curr7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_3day'] = ((county_state_df['state_curr7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_3day'] = ((county_state_df['state_prev7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_3day'] = ((county_state_df['state_prev7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_7day'] = ((county_state_df['state_curr7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_7day'] = ((county_state_df['state_curr7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_7day'] = ((county_state_df['state_prev7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_7day'] = ((county_state_df['state_prev7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_14day'] = ((county_state_df['state_curr7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_14day'] = ((county_state_df['state_curr7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_14day'] = ((county_state_df['state_prev7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_14day'] = ((county_state_df['state_prev7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_state_df['state_roll7case_diff'] = ((county_state_df['state_curr7_case100k']-county_state_df['state_prev7_case100k'])/county_state_df['state_prev7_case100k'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_3day'] = ((county_state_df['state_curr7_case100k_3day']-county_state_df['state_prev7_case100k_3day'])/county_state_df['state_prev7_case100k_3day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_7day'] = ((county_state_df['state_curr7_case100k_7day']-county_state_df['state_prev7_case100k_7day'])/county_state_df['state_prev7_case100k_7day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_14day'] = ((county_state_df['state_curr7_case100k_14day']-county_state_df['state_prev7_case100k_14day'])/county_state_df['state_prev7_case100k_14day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_roll7case_diff_7day  \\\n",
      "0   0.0           0.0                0.0  ...                  -0.173388   \n",
      "1   1.0          13.0                3.0  ...                  -0.173388   \n",
      "2  61.0           6.0                5.0  ...                  -0.173388   \n",
      "3   0.0           0.0                0.0  ...                  -0.173388   \n",
      "4   0.0           0.0                0.0  ...                  -0.173388   \n",
      "\n",
      "  state_roll7case_diff_14day state_roll7death_diff state_prevalence_per100k  \\\n",
      "0                   0.168863              0.337079               273.355796   \n",
      "1                   0.168863              0.337079               273.355796   \n",
      "2                   0.168863              0.337079               273.355796   \n",
      "3                   0.168863              0.337079               273.355796   \n",
      "4                   0.168863              0.337079               273.355796   \n",
      "\n",
      "  state_roll7death_diff_3day  state_prevalence_per100k_3day  \\\n",
      "0                   0.827586                       2.566912   \n",
      "1                   0.827586                       2.566912   \n",
      "2                   0.827586                       2.566912   \n",
      "3                   0.827586                       2.566912   \n",
      "4                   0.827586                       2.566912   \n",
      "\n",
      "   state_roll7death_diff_7day  state_prevalence_per100k_7day  \\\n",
      "0                    1.119048                        2.54654   \n",
      "1                    1.119048                        2.54654   \n",
      "2                    1.119048                        2.54654   \n",
      "3                    1.119048                        2.54654   \n",
      "4                    1.119048                        2.54654   \n",
      "\n",
      "   state_roll7death_diff_14day  state_prevalence_per100k_14day  \n",
      "0                         -0.6                        3.544784  \n",
      "1                         -0.6                        3.544784  \n",
      "2                         -0.6                        3.544784  \n",
      "3                         -0.6                        3.544784  \n",
      "4                         -0.6                        3.544784  \n",
      "\n",
      "[5 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "county_state_df['state_roll7death_diff'] = ((county_state_df['state_curr7_death100k']-county_state_df['state_prev7_death100k'])/county_state_df['state_prev7_death100k'])\n",
    "county_state_df['state_prevalence_per100k'] = ((county_state_df['state_active']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_3day'] = ((county_state_df['state_curr7_death100k_3day']-county_state_df['state_prev7_death100k_3day'])/county_state_df['state_prev7_death100k_3day'])\n",
    "county_state_df['state_prevalence_per100k_3day'] = ((county_state_df['state_active_3']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_7day'] = ((county_state_df['state_curr7_death100k_7day']-county_state_df['state_prev7_death100k_7day'])/county_state_df['state_prev7_death100k_7day'])\n",
    "county_state_df['state_prevalence_per100k_7day'] = ((county_state_df['state_active_7']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_14day'] = ((county_state_df['state_curr7_death100k_14day']-county_state_df['state_prev7_death100k_14day'])/county_state_df['state_prev7_death100k_14day'])\n",
    "county_state_df['state_prevalence_per100k_14day'] = ((county_state_df['state_active_14']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "print(county_state_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID TRACKING PROJ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#Bring in COVID TRACKING data\n",
    "url_all = \"https://covidtracking.com/api/v1/states/daily.csv\"\n",
    "testing_all = pd.read_csv(url_all)\n",
    "testing = testing_all[['date','state','positiveIncrease','negativeIncrease', 'totalTestResultsIncrease']]\n",
    "testing['state_code'] = testing['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date state  positiveIncrease  negativeIncrease  \\\n",
      "0  20201015    AK               165              2119   \n",
      "1  20201015    AL              1185              6939   \n",
      "2  20201015    AR              1278             11592   \n",
      "3  20201015    AS                 0                 0   \n",
      "4  20201015    AZ              1113             10731   \n",
      "5  20201015    CA              3329             88996   \n",
      "6  20201015    CO               692              6600   \n",
      "7  20201015    CT               167             15678   \n",
      "8  20201015    DC                34              2318   \n",
      "9  20201015    DE                95              1715   \n",
      "\n",
      "   totalTestResultsIncrease state_code  \n",
      "0                      2284         AK  \n",
      "1                      7853         AL  \n",
      "2                     12660         AR  \n",
      "3                         0         AS  \n",
      "4                     11831         AZ  \n",
      "5                     92325         CA  \n",
      "6                     14324         CO  \n",
      "7                     15845         CT  \n",
      "8                      2352         DC  \n",
      "9                      1810         DE  \n"
     ]
    }
   ],
   "source": [
    "print(testing.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date state  positiveIncrease  negativeIncrease  \\\n",
      "0  20201015    AK               165              2119   \n",
      "1  20201015    AL              1185              6939   \n",
      "2  20201015    AR              1278             11592   \n",
      "3  20201015    AS                 0                 0   \n",
      "4  20201015    AZ              1113             10731   \n",
      "\n",
      "   totalTestResultsIncrease state_code  curr_pos_%  \n",
      "0                      2284         AK    0.072242  \n",
      "1                      7853         AL    0.150898  \n",
      "2                     12660         AR    0.100948  \n",
      "3                         0         AS         NaN  \n",
      "4                     11831         AZ    0.094075  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "curr_testing = testing[(testing['date']>=curr_test_end) & (testing['date']<=curr_test_start)]\n",
    "curr_testing['curr_pos_%'] = (curr_testing['positiveIncrease']/curr_testing['totalTestResultsIncrease'])\n",
    "print(curr_testing.head())\n",
    "prev_testing = testing[(testing['date']>=prev_test_end) & (testing['date']<=prev_test_start)]\n",
    "prev_testing['prev_pos_%'] = (prev_testing['positiveIncrease']/prev_testing['totalTestResultsIncrease'])\n",
    "\n",
    "#3day#\n",
    "curr_testing_3 = testing[(testing['date']>=curr_test_end_3) & (testing['date']<=curr_test_start_3)]\n",
    "curr_testing_3['curr_pos_%_3'] = (curr_testing_3['positiveIncrease']/curr_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_3 = testing[(testing['date']>=prev_test_end_3) & (testing['date']<=prev_test_start_3)]\n",
    "prev_testing_3['prev_pos_%_3'] = (prev_testing_3['positiveIncrease']/prev_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "#7day#\n",
    "curr_testing_7 = testing[(testing['date']>=curr_test_end_7) & (testing['date']<=curr_test_start_7)]\n",
    "curr_testing_7['curr_pos_%_7'] = (curr_testing_7['positiveIncrease']/curr_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_7 = testing[(testing['date']>=prev_test_end_7) & (testing['date']<=prev_test_start_7)]\n",
    "prev_testing_7['prev_pos_%_7'] = (prev_testing_7['positiveIncrease']/prev_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "#14day#\n",
    "curr_testing_14 = testing[(testing['date']>=curr_test_end_14) & (testing['date']<=curr_test_start_14)]\n",
    "curr_testing_14['curr_pos_%_14'] = (curr_testing_14['positiveIncrease']/curr_testing_14['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_14 = testing[(testing['date']>=prev_test_end_14) & (testing['date']<=prev_test_start_14)]\n",
    "prev_testing_14['prev_pos_%_14'] = (prev_testing_14['positiveIncrease']/prev_testing_14['totalTestResultsIncrease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Group by with mean\n",
    "curr_test_grouped = curr_testing.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped = prev_testing.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#3day#\n",
    "curr_test_grouped_3 = curr_testing_3.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_3 = prev_testing_3.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#7day#\n",
    "curr_test_grouped_7 = curr_testing_7.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_7 = prev_testing_7.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#14day#\n",
    "curr_test_grouped_14 = curr_testing_14.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_14 = prev_testing_14.groupby(['state_code'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_roll7death_diff_3day  \\\n",
      "0   0.0           0.0                0.0  ...                    0.827586   \n",
      "1   1.0          13.0                3.0  ...                    0.827586   \n",
      "2  61.0           6.0                5.0  ...                    0.827586   \n",
      "3   0.0           0.0                0.0  ...                    0.827586   \n",
      "4   0.0           0.0                0.0  ...                    0.827586   \n",
      "\n",
      "  state_prevalence_per100k_3day state_roll7death_diff_7day  \\\n",
      "0                      2.566912                   1.119048   \n",
      "1                      2.566912                   1.119048   \n",
      "2                      2.566912                   1.119048   \n",
      "3                      2.566912                   1.119048   \n",
      "4                      2.566912                   1.119048   \n",
      "\n",
      "  state_prevalence_per100k_7day state_roll7death_diff_14day  \\\n",
      "0                       2.54654                        -0.6   \n",
      "1                       2.54654                        -0.6   \n",
      "2                       2.54654                        -0.6   \n",
      "3                       2.54654                        -0.6   \n",
      "4                       2.54654                        -0.6   \n",
      "\n",
      "   state_prevalence_per100k_14day  curr_pos_%  curr_pos_%_3  curr_pos_%_7  \\\n",
      "0                        3.544784    0.148753      0.138441       0.13359   \n",
      "1                        3.544784    0.148753      0.138441       0.13359   \n",
      "2                        3.544784    0.148753      0.138441       0.13359   \n",
      "3                        3.544784    0.148753      0.138441       0.13359   \n",
      "4                        3.544784    0.148753      0.138441       0.13359   \n",
      "\n",
      "   curr_pos_%_14  \n",
      "0        0.13105  \n",
      "1        0.13105  \n",
      "2        0.13105  \n",
      "3        0.13105  \n",
      "4        0.13105  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge to County Set\n",
    "\n",
    "curr_merge_a = pd.merge(county_state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(curr_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  state_roll7death_diff_14day  \\\n",
      "0   0.0           0.0                0.0  ...                         -0.6   \n",
      "1   1.0          13.0                3.0  ...                         -0.6   \n",
      "2  61.0           6.0                5.0  ...                         -0.6   \n",
      "3   0.0           0.0                0.0  ...                         -0.6   \n",
      "4   0.0           0.0                0.0  ...                         -0.6   \n",
      "\n",
      "  state_prevalence_per100k_14day curr_pos_% curr_pos_%_3 curr_pos_%_7  \\\n",
      "0                       3.544784   0.148753     0.138441      0.13359   \n",
      "1                       3.544784   0.148753     0.138441      0.13359   \n",
      "2                       3.544784   0.148753     0.138441      0.13359   \n",
      "3                       3.544784   0.148753     0.138441      0.13359   \n",
      "4                       3.544784   0.148753     0.138441      0.13359   \n",
      "\n",
      "   curr_pos_%_14  prev_pos_%  prev_pos_%_3  prev_pos_%_7  prev_pos_%_14  \n",
      "0        0.13105     0.13359      0.135608       0.13105       0.136632  \n",
      "1        0.13105     0.13359      0.135608       0.13105       0.136632  \n",
      "2        0.13105     0.13359      0.135608       0.13105       0.136632  \n",
      "3        0.13105     0.13359      0.135608       0.13105       0.136632  \n",
      "4        0.13105     0.13359      0.135608       0.13105       0.136632  \n",
      "\n",
      "[5 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_b = pd.merge(mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_c = pd.merge(mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2 = pd.merge(mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(mam_v2.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_v2['testing_diff'] = (mam_v2['curr_pos_%'] - mam_v2['prev_pos_%'])\n",
    "mam_v2['testing_diff_3'] = (mam_v2['curr_pos_%_3'] - mam_v2['prev_pos_%_3'])\n",
    "mam_v2['testing_diff_7'] = (mam_v2['curr_pos_%_7'] - mam_v2['prev_pos_%_7'])\n",
    "mam_v2['testing_diff_14'] = (mam_v2['curr_pos_%_14'] - mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State state_code  Level 6  NBCU  Tech Ops EE Count  \\\n",
      "0  01073   Jefferson  Alabama         AL      NaN  33.0                0.0   \n",
      "1  01097      Mobile  Alabama         AL      NaN   4.0               64.0   \n",
      "2  01089     Madison  Alabama         AL      NaN   4.0               41.0   \n",
      "3  01101  Montgomery  Alabama         AL      NaN   7.0                0.0   \n",
      "4  01003     Baldwin  Alabama         AL      NaN   3.0                0.0   \n",
      "\n",
      "    CAE  Cable Stores  Business Services  ...  curr_pos_%_7 curr_pos_%_14  \\\n",
      "0   0.0           0.0                0.0  ...       0.13359       0.13105   \n",
      "1   1.0          13.0                3.0  ...       0.13359       0.13105   \n",
      "2  61.0           6.0                5.0  ...       0.13359       0.13105   \n",
      "3   0.0           0.0                0.0  ...       0.13359       0.13105   \n",
      "4   0.0           0.0                0.0  ...       0.13359       0.13105   \n",
      "\n",
      "  prev_pos_% prev_pos_%_3 prev_pos_%_7  prev_pos_%_14  testing_diff  \\\n",
      "0    0.13359     0.135608      0.13105       0.136632      0.015162   \n",
      "1    0.13359     0.135608      0.13105       0.136632      0.015162   \n",
      "2    0.13359     0.135608      0.13105       0.136632      0.015162   \n",
      "3    0.13359     0.135608      0.13105       0.136632      0.015162   \n",
      "4    0.13359     0.135608      0.13105       0.136632      0.015162   \n",
      "\n",
      "   testing_diff_3  testing_diff_7  testing_diff_14  \n",
      "0        0.002834        0.002541        -0.005582  \n",
      "1        0.002834        0.002541        -0.005582  \n",
      "2        0.002834        0.002541        -0.005582  \n",
      "3        0.002834        0.002541        -0.005582  \n",
      "4        0.002834        0.002541        -0.005582  \n",
      "\n",
      "[5 rows x 127 columns]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "###Filter out any counties with 0 cases for past 14 days##\n",
    "\n",
    "\n",
    "#county_filtered = mam_v2[(mam_v2['active_cases_100k']>=0)]\n",
    "county_filtered = mam_v2\n",
    "print(mam_v2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 7/1\n",
    "\n",
    "def active(n):\n",
    "    if 0<=n<=49.48: score = 0\n",
    "    elif 49.49<=n<=114.05: score = 1\n",
    "    elif 114.06<=n<=100000: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "\n",
    "def roll(n):\n",
    "    if -1<=n<=-0.10: score = 0\n",
    "    elif -0.10<=n<=0.10: score = 1\n",
    "    elif 0.101111<=n<=100: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 0.5  \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd_state(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 1 \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_indicator(n):\n",
    "    if -10000<=n<0.10: score = \"Decreasing or Steady\"\n",
    "    elif 0.10<=n<=10000: score = \"Increasing\"  \n",
    "    else: score = \"Decreasing or Steady\"\n",
    "    return(score)\n",
    "\n",
    "#def test(n):\n",
    "#    if -2<=n<=-.01: score = 0\n",
    "#    elif -.011111<=n<=.01: score = 1\n",
    "#    elif 0.01111 <=n<= 100: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def test7(n):\n",
    "    if -2<=n< 0.03: score = 0\n",
    "    elif 0.03 <=n<.1: score =1\n",
    "    elif 0.1 <=n<0.15: score =2\n",
    "    elif 0.15 <=n<= 1000: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def curr7(n):\n",
    "#    if -2<=n<=4.9999: score = 0\n",
    "#    elif 5 <=n<=9.9999: score =1\n",
    "#    elif 10 <=n<=99999: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def curr7_hrvd(n):\n",
    "    if -222<=n<= 2: score = 0\n",
    "    elif 2 <n<10: score =1\n",
    "    elif 10 <=n<25: score =2\n",
    "    elif 25 <=n<=99999: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def testch(n):\n",
    "    if 0<=n<=0.1: score = 'Decreasing'\n",
    "    elif 1 <=n<= 1.9: score = 'Steady'\n",
    "    else: score = 'Increasing'\n",
    "    return(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_filtered['County_Active_100k_Score'] = county_filtered['active_cases_100k'].apply(active)\n",
    "county_filtered['State_Active_100k_Score'] = county_filtered['state_prevalence_per100k'].apply(active)\n",
    "county_filtered['County_Roll_Score'] = county_filtered['roll7case_diff'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend'] = county_filtered['roll7case_diff'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score'] = county_filtered['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score'] = county_filtered['testing_diff'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg'] = county_filtered['curr_pos_%'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg'] = county_filtered['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg'] = county_filtered['cur_7rollavg_cases'].apply(curr7_hrvd)\n",
    "\n",
    "#3day#\n",
    "county_filtered_3day = county_filtered\n",
    "county_filtered['County_Active_100k_Score_3'] = county_filtered['active_cases_100k_3day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_3'] = county_filtered['state_prevalence_per100k_3day'].apply(active)\n",
    "county_filtered['County_Roll_Score_3'] = county_filtered['roll7case_diff_3day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_3'] = county_filtered['roll7case_diff_3day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_3'] = county_filtered['state_roll7case_diff_3day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_3'] = county_filtered['testing_diff_3'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_3'] = county_filtered['curr_pos_%_3'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_3'] = county_filtered['state_curr7_case100k_3day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_3'] = county_filtered['cur_7rollavg_cases_3day'].apply(curr7_hrvd)\n",
    "\n",
    "#7day#\n",
    "county_filtered['County_Active_100k_Score_7'] = county_filtered['active_cases_100k_7day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_7'] = county_filtered['state_prevalence_per100k_7day'].apply(active)\n",
    "county_filtered['County_Roll_Score_7'] = county_filtered['roll7case_diff_7day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_7'] = county_filtered['roll7case_diff_7day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_7'] = county_filtered['state_roll7case_diff_7day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_7'] = county_filtered['testing_diff_7'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_7'] = county_filtered['curr_pos_%_7'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_7'] = county_filtered['state_curr7_case100k_7day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_7'] = county_filtered['cur_7rollavg_cases_7day'].apply(curr7_hrvd)\n",
    "\n",
    "#14day#\n",
    "county_filtered['County_Active_100k_Score_14'] = county_filtered['active_cases_100k_14day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_14'] = county_filtered['state_prevalence_per100k_14day'].apply(active)\n",
    "county_filtered['County_Roll_Score_14'] = county_filtered['roll7case_diff_14day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_14'] = county_filtered['roll7case_diff_14day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_14'] = county_filtered['state_roll7case_diff_14day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_14'] = county_filtered['testing_diff_14'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_14'] = county_filtered['curr_pos_%_14'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_14'] = county_filtered['state_curr7_case100k_14day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_14'] = county_filtered['cur_7rollavg_cases_14day'].apply(curr7_hrvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_filtered['State_Composite_Score'] =  ( county_filtered['State_Roll_Score']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "county_filtered['County_Composite_Score'] = (county_filtered['County_Roll_Score'] + county_filtered['County_7Day_New_Case_Rolling_Avg'])\n",
    "\n",
    "#3day#\n",
    "county_filtered['State_Composite_Score_3'] =  ( county_filtered['State_Roll_Score_3']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "county_filtered['County_Composite_Score_3'] = (county_filtered['County_Roll_Score_3'] + county_filtered['County_7Day_New_Case_Rolling_Avg_3'])\n",
    "\n",
    "\n",
    "# #7 day#\n",
    "county_filtered['State_Composite_Score_7'] =  ( county_filtered['State_Roll_Score_7']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "county_filtered['County_Composite_Score_7'] = (county_filtered['County_Roll_Score_7'] + county_filtered['County_7Day_New_Case_Rolling_Avg_7'])\n",
    "\n",
    "\n",
    "# #14 day#\n",
    "county_filtered['State_Composite_Score_14'] =  ( county_filtered['State_Roll_Score_14']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "county_filtered['County_Composite_Score_14'] = (county_filtered['County_Roll_Score_14'] + county_filtered['County_7Day_New_Case_Rolling_Avg_14'])\n",
    "\n",
    "# county_filtered.to_csv(\"Checkcc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def county(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 0.1<=n<=1: score = \"Low\"\n",
    "#    elif 1<n<=2: score = \"Moderate\"\n",
    "#    elif 2<n<=3: score = \"Severe\"\n",
    "#    elif 4<=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def county_hrvd(n):\n",
    "    if 0<=n<0.5: score = \"Minimal\"\n",
    "    elif 0.5<=n<1: score = \"Low\"\n",
    "    elif 1<=n<2: score = \"Moderate\"\n",
    "    elif 2<=n<3: score = \"Elevated\"\n",
    "    elif 3<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "def state(n):\n",
    "    if 0<=n<1: score = \"Minimal\"\n",
    "    elif 1<=n<2: score = \"Low\"\n",
    "    elif 2<=n<4: score = \"Moderate\"\n",
    "    elif 4<=n<6: score = \"Elevated\"\n",
    "    elif 6<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def blend(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 1<=n<=2: score = \"Low\"\n",
    "#    elif 3<=n<=4: score = \"Moderate\"\n",
    "#    elif 5<=n<=6: score = \"Severe\"\n",
    "#    elif 7 <=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "county_filtered['County_Level'] = county_filtered['County_Composite_Score'].apply(county_hrvd)\n",
    "county_filtered['State_Level'] = county_filtered['State_Composite_Score'].apply(state)\n",
    "#county_filtered['County_State_Blend'] = ((county_filtered['County_Composite_Score']+county_filtered['State_Composite_Score']))\n",
    "#county_filtered['County_State_Level'] = county_filtered['County_State_Blend'].apply(blend)\n",
    "\n",
    "#3day, 7 day, 14 day#\n",
    "county_filtered['County_Level_3'] = county_filtered['County_Composite_Score_3'].apply(county_hrvd)\n",
    "county_filtered['State_Level_3'] = county_filtered['State_Composite_Score_3'].apply(state)\n",
    "county_filtered['County_Level_7'] = county_filtered['County_Composite_Score_7'].apply(county_hrvd)\n",
    "county_filtered['State_Level_7'] = county_filtered['State_Composite_Score_7'].apply(state)\n",
    "county_filtered['County_Level_14'] = county_filtered['County_Composite_Score_14'].apply(county_hrvd)\n",
    "county_filtered['State_Level_14'] = county_filtered['State_Composite_Score_14'].apply(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips      County    State County_Level State_Level  \\\n",
      "0  01073   Jefferson  Alabama     Elevated    Elevated   \n",
      "1  01097      Mobile  Alabama     Elevated    Elevated   \n",
      "2  01089     Madison  Alabama     Elevated    Elevated   \n",
      "3  01101  Montgomery  Alabama     Elevated    Elevated   \n",
      "4  01003     Baldwin  Alabama     Moderate    Elevated   \n",
      "\n",
      "   County_Composite_Score  curr7_case  cur_7rollavg_cases  \\\n",
      "0                     2.5  133.142857           20.216871   \n",
      "1                     2.5   41.571429           10.060606   \n",
      "2                     2.5   52.428571           14.059347   \n",
      "3                     2.5   49.428571           21.824118   \n",
      "4                     1.0   20.571429            9.215186   \n",
      "\n",
      "      County Case Trend  roll7case_diff  ...  County_Level_3 County_Level_7  \\\n",
      "0            Increasing        0.418569  ...        Elevated       Elevated   \n",
      "1            Increasing        0.385714  ...        Moderate       Moderate   \n",
      "2            Increasing        0.150470  ...        Elevated       Elevated   \n",
      "3            Increasing        0.830688  ...        Elevated       Elevated   \n",
      "4  Decreasing or Steady        0.000000  ...        Moderate       Moderate   \n",
      "\n",
      "  County_Level_14 New Cases per 100k_7 dayavg  \\\n",
      "0        Elevated                   20.216871   \n",
      "1        Elevated                   10.060606   \n",
      "2        Elevated                   14.059347   \n",
      "3        Moderate                   21.824118   \n",
      "4        Critical                    9.215186   \n",
      "\n",
      "   Historical County Composite Score_3Days Back  \\\n",
      "0                                      Elevated   \n",
      "1                                      Moderate   \n",
      "2                                      Elevated   \n",
      "3                                      Elevated   \n",
      "4                                      Moderate   \n",
      "\n",
      "  Historical County Composite Score_7Days Back  \\\n",
      "0                                     Elevated   \n",
      "1                                     Moderate   \n",
      "2                                     Elevated   \n",
      "3                                     Elevated   \n",
      "4                                     Moderate   \n",
      "\n",
      "  Historical County Composite Score_14Days Back WOW Case Trend %  \\\n",
      "0                                      Elevated         0.418569   \n",
      "1                                      Elevated         0.385714   \n",
      "2                                      Elevated         0.150470   \n",
      "3                                      Moderate         0.830688   \n",
      "4                                      Critical         0.000000   \n",
      "\n",
      "   Prior WOW Case Trend %  Less than 50 New Cases  \n",
      "0               -0.242215                          \n",
      "1               -0.396552                       Y  \n",
      "2                0.056291                          \n",
      "3                0.350000                       Y  \n",
      "4               -0.826923                       Y  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "##ADD FIELDS FOR LOOK BACKS HERE\n",
    "\n",
    "county_fields = county_filtered[['fips',\n",
    "    'County','State','County_Level', 'State_Level', 'County_Composite_Score','curr7_case',\n",
    "                                 'cur_7rollavg_cases','County Case Trend',  'roll7case_diff', \n",
    "                                 'roll7case_diff_7day',\n",
    "#                                  'Total CCC','CAE','Cable Stores','Business Services', 'Tech Ops EE Count',\n",
    "                                'County_Level_3',\n",
    "#                                  'State_Level_3', \n",
    "                                'County_Level_7',\n",
    "#                                  'State_Level_7', \n",
    "                                'County_Level_14'\n",
    "#                                  ,'State_Level_14'\n",
    "                                ]]\n",
    "\n",
    "county_fields['New Cases per 100k_7 dayavg'] = county_fields['cur_7rollavg_cases']\n",
    "county_fields['Historical County Composite Score_3Days Back'] = county_fields['County_Level_3']\n",
    "county_fields['Historical County Composite Score_7Days Back'] = county_fields['County_Level_7']\n",
    "county_fields['Historical County Composite Score_14Days Back'] = county_fields['County_Level_14']\n",
    "county_fields['WOW Case Trend %'] = county_fields['roll7case_diff']\n",
    "county_fields['Prior WOW Case Trend %'] = county_fields['roll7case_diff_7day']\n",
    "county_fields['Less than 50 New Cases'] = np.where(county_fields['curr7_case'] < 50, \"Y\",\"\")\n",
    "\n",
    "# print(county_fields.dtypes)\n",
    "\n",
    "# def less_than_50(n):\n",
    "#     if n < 50: score = 1\n",
    "#     else: score = 0\n",
    "#     return(score)\n",
    "# county_fields['Less_than_50'] = county_fields['curr7_case'].apply(less_than_50)\n",
    "\n",
    "county_fields_csv = county_fields[['fips','County','State','County_Level','State_Level','County_Composite_Score',\n",
    "                                  'New Cases per 100k_7 dayavg','Less than 50 New Cases','WOW Case Trend %','Prior WOW Case Trend %',\n",
    "                                   'County Case Trend','Historical County Composite Score_3Days Back',\n",
    "                                  'Historical County Composite Score_7Days Back', 'Historical County Composite Score_14Days Back']]\n",
    "print(county_fields.head())\n",
    "county_fields_csv.to_csv(file,index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create State Only File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge state data with state base file \n",
    "\n",
    "state_active_a= pd.merge(state_pop_df,\n",
    "                 state_prevalence_grouped[['State','state_active',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "#3,7,14 day#\n",
    "state_active_b= pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_c= pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active= pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day',\n",
    "                                       'state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day',\n",
    "                                       'state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day',\n",
    "                                       'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_b = pd.merge(state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_c = pd.merge(state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df = pd.merge(state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create State Level metrics\n",
    "\n",
    "state_df['state_curr7_case100k'] = ((state_df['state_curr7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k'] = ((state_df['state_curr7_death']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k'] = ((state_df['state_prev7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k'] = ((state_df['state_prev7_death']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff'] = ((state_df['state_curr7_case100k']-state_df['state_prev7_case100k'])/state_df['state_prev7_case100k'])\n",
    "state_df['state_roll7death_diff'] = ((state_df['state_curr7_death100k']-state_df['state_prev7_death100k'])/state_df['state_prev7_death100k'])\n",
    "state_df['state_prevalence_per100k'] = ((state_df['state_active']/state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3day\n",
    "state_df['state_curr7_case100k_3'] = ((state_df['state_curr7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_3'] = ((state_df['state_curr7_death_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_3'] = ((state_df['state_prev7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_3'] = ((state_df['state_prev7_death_3day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_3'] = ((state_df['state_curr7_case100k_3']-state_df['state_prev7_case100k_3'])/state_df['state_prev7_case100k_3'])\n",
    "state_df['state_roll7death_diff_3'] = ((state_df['state_curr7_death100k_3']-state_df['state_prev7_death100k_3'])/state_df['state_prev7_death100k_3'])\n",
    "state_df['state_prevalence_per100k_3'] = ((state_df['state_active_3']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "#7day\n",
    "state_df['state_curr7_case100k_7'] = ((state_df['state_curr7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_7'] = ((state_df['state_curr7_death_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_7'] = ((state_df['state_prev7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_7'] = ((state_df['state_prev7_death_7day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_7'] = ((state_df['state_curr7_case100k_7']-state_df['state_prev7_case100k_7'])/state_df['state_prev7_case100k_7'])\n",
    "state_df['state_roll7death_diff_7'] = ((state_df['state_curr7_death100k_7']-state_df['state_prev7_death100k_7'])/state_df['state_prev7_death100k_7'])\n",
    "state_df['state_prevalence_per100k_7'] = ((state_df['state_active_7']/state_df['state_pop'])*100000)\n",
    "\n",
    "#14day\n",
    "state_df['state_curr7_case100k_14'] = ((state_df['state_curr7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_14'] = ((state_df['state_curr7_death_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_14'] = ((state_df['state_prev7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_14'] = ((state_df['state_prev7_death_14day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_14'] = ((state_df['state_curr7_case100k_14']-state_df['state_prev7_case100k_14'])/state_df['state_prev7_case100k_14'])\n",
    "state_df['state_roll7death_diff_14'] = ((state_df['state_curr7_death100k_14']-state_df['state_prev7_death100k_14'])/state_df['state_prev7_death100k_14'])\n",
    "state_df['state_prevalence_per100k_14'] = ((state_df['state_active_14']/state_df['state_pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Covid Tracking Data\n",
    "\n",
    "\n",
    "curr_merge_a = pd.merge(state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']], on='state_code', how='left')\n",
    "\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_b = pd.merge(state_mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_c = pd.merge(state_mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2 = pd.merge(state_mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14',]],\n",
    "                 on='state_code', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_mam_v2['testing_diff'] = (state_mam_v2['curr_pos_%'] - state_mam_v2['prev_pos_%'])\n",
    "state_mam_v2['testing_diff_3'] = (state_mam_v2['curr_pos_%_3'] - state_mam_v2['prev_pos_%_3'])\n",
    "state_mam_v2['testing_diff_7'] = (state_mam_v2['curr_pos_%_7'] - state_mam_v2['prev_pos_%_7'])\n",
    "state_mam_v2['testing_diff_14'] = (state_mam_v2['curr_pos_%_14'] - state_mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Level Scores\n",
    "\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score'] = state_mam_v2['state_prevalence_per100k'].apply(active)\n",
    "state_mam_v2['State_Roll_Score'] = state_mam_v2['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg'] = state_mam_v2['curr_pos_%'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg'] = state_mam_v2['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "\n",
    "#3,7,14 day\n",
    "state_mam_v2['State_Active_100k_Score_3'] = state_mam_v2['state_prevalence_per100k_3'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_3'] = state_mam_v2['state_roll7case_diff_3'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_3'] = state_mam_v2['curr_pos_%_3'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_3'] = state_mam_v2['state_curr7_case100k_3'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_7'] = state_mam_v2['state_prevalence_per100k_7'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_7'] = state_mam_v2['state_roll7case_diff_7'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_7'] = state_mam_v2['curr_pos_%_7'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_7'] = state_mam_v2['state_curr7_case100k_7'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_14'] = state_mam_v2['state_prevalence_per100k_14'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_14'] = state_mam_v2['state_roll7case_diff_14'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_14'] = state_mam_v2['curr_pos_%_14'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_14'] = state_mam_v2['state_curr7_case100k_14'].apply(curr7_hrvd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final dataset\n",
    "\n",
    "state_mam_v2['State Composite Score'] =  (  state_mam_v2['State_Roll_Score']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "state_mam_v2['State Classification'] = state_mam_v2['State Composite Score'].apply(state)\n",
    "#state_mam_v2['Test_Change_Classification'] = state_mam_v2['State_Testing_Score'].apply(testch)\n",
    "\n",
    "\n",
    "#3day\n",
    "state_mam_v2['State Composite Score_3'] =  (  state_mam_v2['State_Roll_Score_3']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "state_mam_v2['State Classification_3'] = state_mam_v2['State Composite Score_3'].apply(state)\n",
    "\n",
    "#7day\n",
    "state_mam_v2['State Composite Score_7'] =  (  state_mam_v2['State_Roll_Score_7']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "state_mam_v2['State Classification_7'] = state_mam_v2['State Composite Score_7'].apply(state)\n",
    "\n",
    "#14 day\n",
    "state_mam_v2['State Composite Score_14'] =  (  state_mam_v2['State_Roll_Score_14']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "state_mam_v2['State Classification_14'] = state_mam_v2['State Composite Score_14'].apply(state)\n",
    "\n",
    "# final_state_df = state_mam_v2.query('comcast_state ==1')\n",
    "final_state_df = state_mam_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State State Classification  State Composite Score  \\\n",
      "0     Alabama             Elevated                      5   \n",
      "1      Alaska             Moderate                      3   \n",
      "2     Arizona             Elevated                      4   \n",
      "3    Arkansas             Elevated                      5   \n",
      "4  California                  Low                      1   \n",
      "\n",
      "   New Cases p 100K_7 day avg  Positive Test %_7 day avg  WOW Case Trend %  \\\n",
      "0                   20.916552                   0.148753          0.153426   \n",
      "1                    6.341374                   0.060295          0.247919   \n",
      "2                   10.340864                   0.078393          0.273790   \n",
      "3                   29.986378                   0.086175          0.198159   \n",
      "4                    8.225712                   0.027338         -0.003553   \n",
      "\n",
      "  Historical State Composite Score_3Days Back  \\\n",
      "0                                    Elevated   \n",
      "1                                    Moderate   \n",
      "2                                    Moderate   \n",
      "3                                    Elevated   \n",
      "4                                         Low   \n",
      "\n",
      "  Historical State Composite Score_7Days Back  \\\n",
      "0                                    Elevated   \n",
      "1                                    Moderate   \n",
      "2                                    Moderate   \n",
      "3                                    Elevated   \n",
      "4                                         Low   \n",
      "\n",
      "  Historical State Composite Score_14Days Back  \n",
      "0                                     Elevated  \n",
      "1                                     Moderate  \n",
      "2                                     Moderate  \n",
      "3                                     Elevated  \n",
      "4                                     Moderate  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Export State File to CSV\n",
    "\n",
    "final_state_df2 = final_state_df[['State', 'State Classification', 'State Composite Score','state_curr7_case100k','curr_pos_%',\n",
    "                                  'state_roll7case_diff', \n",
    "#                                   'State_Roll_Score',\n",
    "                                 'State_7Day_Pos_Test_Avg','State_7Day_New_Case_Rolling_Avg',\n",
    "#                                  'Comcast Employees','CAE','Cable Stores','Business Services', 'Tech Ops','Warehouse',\n",
    "                                 'State Classification_3',\n",
    "                                 'State Classification_7',\n",
    "                                 'State Classification_14']]\n",
    "\n",
    "final_state_df2['New Cases p 100K_7 day avg'] =  final_state_df2['state_curr7_case100k']\n",
    "final_state_df2['Positive Test %_7 day avg'] =  final_state_df2['curr_pos_%']\n",
    "final_state_df2['WOW Case Trend %'] =  final_state_df2['state_roll7case_diff']\n",
    "final_state_df2['Historical State Composite Score_3Days Back'] =  final_state_df2['State Classification_3']\n",
    "final_state_df2['Historical State Composite Score_7Days Back'] =  final_state_df2['State Classification_7']\n",
    "final_state_df2['Historical State Composite Score_14Days Back'] =  final_state_df2['State Classification_14']\n",
    "\n",
    "final_state_csv = final_state_df2[['State','State Classification', 'State Composite Score', 'New Cases p 100K_7 day avg',\n",
    "                                'Positive Test %_7 day avg','WOW Case Trend %','Historical State Composite Score_3Days Back',\n",
    "                                  'Historical State Composite Score_7Days Back','Historical State Composite Score_14Days Back']]\n",
    "print(final_state_csv.head())\n",
    "final_state_csv.to_csv(state_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State state_code  Comcast Employees  state_pop  CAE  Cable Stores  \\\n",
      "0     Alabama         AL                391    4908621   65            36   \n",
      "1      Alaska         AK                  0    3038999    0             0   \n",
      "2     Arizona         AZ                720    7378494  227            17   \n",
      "3    Arkansas         AR                112    3038999    1            10   \n",
      "4  California         CA               4747   39937489   87           471   \n",
      "\n",
      "   Business Services  Tech Ops  Warehouse  comcast_state  NBCU_pop  \n",
      "0                  8       191         10              1         0  \n",
      "1                  0         0          0              0         0  \n",
      "2                  5        86          2              1       335  \n",
      "3                  7        62          4              1        56  \n",
      "4                215      1966         50              1     12431  \n"
     ]
    }
   ],
   "source": [
    "print(state_pop_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
