{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTW MAM Model V1 \n",
    "# County Data First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current\n",
      "2020-08-04\n",
      "2020-07-29\n",
      "2020-07-28\n",
      "2020-07-22\n",
      "3 day\n",
      "2020-08-01\n",
      "2020-07-26\n",
      "2020-07-25\n",
      "2020-07-19\n",
      "7 day\n",
      "2020-07-28\n",
      "2020-07-22\n",
      "2020-07-21\n",
      "2020-07-15\n",
      "14 day\n",
      "2020-07-21\n",
      "2020-07-15\n",
      "2020-07-14\n",
      "2020-07-08\n"
     ]
    }
   ],
   "source": [
    "#SET DATE FILTERS & FileName\n",
    "\n",
    "file = 'CountyMAM2_AUG4_.csv'\n",
    "state_file = 'State_MAM2_AUG4_.csv'\n",
    "\n",
    "\n",
    "preval_end = datetime.today()- timedelta(days=1)\n",
    "preval_end = datetime.strftime(preval_end,'%Y-%m-%d')\n",
    "\n",
    "preval_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=13)\n",
    "preval_start = preval_start.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=6)\n",
    "curr_start = curr_start.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end = datetime.strptime(preval_end,'%Y-%m-%d')\n",
    "curr_end = curr_end.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=13)\n",
    "prev_start = prev_start.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end = datetime.strptime(preval_end,'%Y-%m-%d') - timedelta(days=7)\n",
    "prev_end = prev_end.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "#Add 3 more for 3 day look back, 7 day, 14 day##\n",
    "##3 DAY HISTORICAL LOOK BACK##\n",
    "\n",
    "preval_start_3 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_start_3 = preval_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_3 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "preval_end_3 = preval_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_3 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_start_3 = curr_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_3 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "curr_end_3 = curr_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_3 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_start_3 = prev_start_3.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_3 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=3)\n",
    "prev_end_3 = prev_end_3.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##7 DAY HISTORICAL LOOK BACK##\n",
    "preval_start_7 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_start_7 = preval_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_7 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "preval_end_7 = preval_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_7 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_start_7 = curr_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_7 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "curr_end_7 = curr_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_7 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_start_7 = prev_start_7.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_7 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=7)\n",
    "prev_end_7 = prev_end_7.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# ##14 HISTORICAL DAY LOOK BACK##\n",
    "preval_start_14 = datetime.strptime(preval_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_start_14 = preval_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "preval_end_14 = datetime.strptime(preval_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "preval_end_14 = preval_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_start_14 = datetime.strptime(curr_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_start_14 = curr_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "curr_end_14 = datetime.strptime(curr_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "curr_end_14 = curr_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_start_14 = datetime.strptime(prev_start, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_start_14 = prev_start_14.strftime('%Y-%m-%d')\n",
    "\n",
    "prev_end_14 = datetime.strptime(prev_end, \"%Y-%m-%d\") - timedelta(days=14)\n",
    "prev_end_14 = prev_end_14.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"Current\")\n",
    "# print(preval_start)\n",
    "# print(preval_end)\n",
    "print(curr_end)\n",
    "print(curr_start)\n",
    "print(prev_end)\n",
    "print(prev_start)\n",
    "\n",
    "\n",
    "print(\"3 day\")\n",
    "print(curr_end_3)\n",
    "print(curr_start_3)\n",
    "print(prev_end_3)\n",
    "print(prev_start_3)\n",
    "\n",
    "print(\"7 day\")\n",
    "print(curr_end_7)\n",
    "print(curr_start_7)\n",
    "print(prev_end_7)\n",
    "print(prev_start_7)\n",
    "\n",
    "print(\"14 day\")\n",
    "print(curr_end_14)\n",
    "print(curr_start_14)\n",
    "print(prev_end_14)\n",
    "print(prev_start_14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_test_start = int(curr_end.replace('-',''))\n",
    "curr_test_end = int(curr_start.replace('-',''))\n",
    "prev_test_start = int(prev_end.replace('-',''))\n",
    "prev_test_end = int(prev_start.replace('-',''))\n",
    "\n",
    "##3 day look back##\n",
    "\n",
    "curr_test_start_3 = int(curr_end_3.replace('-',''))\n",
    "curr_test_end_3 = int(curr_start_3.replace('-',''))\n",
    "prev_test_start_3 = int(prev_end_3.replace('-',''))\n",
    "prev_test_end_3 = int(prev_start_3.replace('-',''))\n",
    "\n",
    "##7day look back##\n",
    "curr_test_start_7 =int(curr_end_7.replace('-',''))\n",
    "curr_test_end_7 = int(curr_start_7.replace('-',''))\n",
    "prev_test_start_7 = int(prev_end_7.replace('-',''))\n",
    "prev_test_end_7 = int(prev_start_7.replace('-',''))\n",
    "\n",
    "##14 day look back##\n",
    "curr_test_start_14 = int(curr_end_14.replace('-',''))\n",
    "curr_test_end_14 = int(curr_start_14.replace('-',''))\n",
    "prev_test_start_14 = int(prev_end_14.replace('-',''))\n",
    "prev_test_end_14 = int(prev_start_14.replace('-',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATES NEEDED - bring in base file, within base file add in state 2 digit codes\n",
    "#Need to add in the NYC FIPS dummy code\n",
    "\n",
    "#Bring in County Data set\n",
    "nytimes = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "counties = pd.read_csv(nytimes,dtype={'fips': str})\n",
    "\n",
    "\n",
    "\n",
    "base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/base_rtw_v2.csv\"\n",
    "pop_df = pd.read_csv(base,\n",
    "                dtype={'fips': str})\n",
    "\n",
    "state_base = \"https://raw.githubusercontent.com/dherlund/COVID_MAM/master/state_base_v1.csv\"\n",
    "state_pop_df = pd.read_csv(state_base)\n",
    "#pop_df = pd.read_csv(\"base_rtw_v1.csv\",\n",
    "#                dtype={'fips': str})\n",
    "\n",
    "#base['fips2'] = np.where(base['county']=='New York City','36061',base['fips'])\n",
    "\n",
    "counties.loc[counties['county'] == 'New York City', 'fips'] = '36061'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Active Case Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date   county    state   fips  cases  deaths\n",
      "9480   2020-03-24  Autauga  Alabama  01001      1       0\n",
      "10835  2020-03-25  Autauga  Alabama  01001      4       0\n",
      "12367  2020-03-26  Autauga  Alabama  01001      6       0\n",
      "14025  2020-03-27  Autauga  Alabama  01001      6       0\n",
      "15803  2020-03-28  Autauga  Alabama  01001      6       0\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "counties.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(counties.head())\n",
    "\n",
    "#Take difference between rows for new case and new death numbers\n",
    "counties['case_diff'] = counties.cases.diff()\n",
    "counties['death_diff'] = counties.deaths.diff()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for past 14 days\n",
    "#range_14 = counties[counties['date']>=preval_start]\n",
    "\n",
    "range_14 = counties[(counties['date']>=preval_start) & (counties['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = counties[(counties['date']>=preval_start_3) & (counties['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = counties[(counties['date']>=preval_start_7) & (counties['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = counties[(counties['date']>=preval_start_14) & (counties['date']<=preval_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by FIPS, sum up new Cases for prevalence - for 7 day averages will take mean after filtering for 7 days\n",
    "prevalence_grouped = range_14.groupby(['fips'], as_index=False).sum()\n",
    "\n",
    "#3 day#\n",
    "prevalence_grouped_3 = range_14_3.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_3[\"case_diff_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "prevalence_grouped_7 = range_14_7.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_7[\"case_diff_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "prevalence_grouped_14 = range_14_14.groupby(['fips'], as_index=False).sum()\n",
    "prevalence_grouped_14[\"case_diff_14\"] = prevalence_grouped_14[\"case_diff\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join in Prevalence to \n",
    "prevalence_w_pop_a = pd.merge(pop_df,\n",
    "                 prevalence_grouped[['fips','case_diff']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_b = pd.merge(prevalence_w_pop_a,\n",
    "                 prevalence_grouped_3[['fips','case_diff_3']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "prevalence_w_pop_c = pd.merge(prevalence_w_pop_b,\n",
    "                 prevalence_grouped_7[['fips','case_diff_7']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "prevalence_w_pop = pd.merge(prevalence_w_pop_c,\n",
    "                 prevalence_grouped_14[['fips','case_diff_14']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  state_pop  \\\n",
      "0                  0    0             0                  0  ...   20100000   \n",
      "1                  0    0             0                  2  ...   39937489   \n",
      "2                965  356           201                146  ...   12659682   \n",
      "3                  0    0             0                  0  ...   29472295   \n",
      "4                  0    0             0                  3  ...    7378494   \n",
      "\n",
      "  Homeloc_count_CCC case_diff case_diff_3 case_diff_7  case_diff_14  \\\n",
      "0               673    4185.0      4348.0      4646.0        4623.0   \n",
      "1                93   33941.0     37652.0     38335.0       41134.0   \n",
      "2              3577    8280.0      7839.0      7255.0        6411.0   \n",
      "3                 0      14.0        16.0        11.0          13.0   \n",
      "4                 9   22801.0     25425.0     27213.0       31445.0   \n",
      "\n",
      "   active_cases_100k  active_cases_100k_3day  active_cases_100k_7day  \\\n",
      "0          22.255903               23.122740               24.707509   \n",
      "1         338.087840              375.053279              381.856673   \n",
      "2         160.769425              152.206706              140.867413   \n",
      "3         259.307279              296.351176              203.741434   \n",
      "4         508.336577              566.837309              606.699850   \n",
      "\n",
      "   active_cases_100k_14day  \n",
      "0                24.585195  \n",
      "1               409.737639  \n",
      "2               124.479805  \n",
      "3               240.785331  \n",
      "4               701.050115  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "prevalence_w_pop['active_cases_100k'] = ((prevalence_w_pop['case_diff']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_3day'] = ((prevalence_w_pop['case_diff_3']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_7day'] = ((prevalence_w_pop['case_diff_7']/prevalence_w_pop['pop'])*100000)\n",
    "\n",
    "prevalence_w_pop['active_cases_100k_14day'] = ((prevalence_w_pop['case_diff_14']/prevalence_w_pop['pop'])*100000)\n",
    "print(prevalence_w_pop.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create 7 Day Rolling Avgs for Cases & Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter Diff datasets for current and previous 7 day periods\n",
    "\n",
    "#join prev and current together with pop\n",
    "\n",
    "range_current7 = counties[(counties['date']>=curr_start) & (counties['date']<=curr_end)]\n",
    "range_prev7 = counties[(counties['date']>=prev_start) & (counties['date']<=prev_end)]\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "range_current7_3 = counties[(counties['date']>=curr_start_3) & (counties['date']<=curr_end_3)]\n",
    "range_prev7_3 = counties[(counties['date']>=prev_start_3) & (counties['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "range_current7_7 = counties[(counties['date']>=curr_start_7) & (counties['date']<=curr_end_7)]\n",
    "range_prev7_7 = counties[(counties['date']>=prev_start_7) & (counties['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "range_current7_14 = counties[(counties['date']>=curr_start_14) & (counties['date']<=curr_end_14)]\n",
    "range_prev7_14 = counties[(counties['date']>=prev_start_14) & (counties['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by with mean\n",
    "current_grouped = range_current7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped = range_prev7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped['curr7_case'] = current_grouped['case_diff']\n",
    "current_grouped['curr7_death'] = current_grouped['death_diff']\n",
    "previous_grouped['prev7_case'] = previous_grouped['case_diff']\n",
    "previous_grouped['prev7_death'] = previous_grouped['death_diff']\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "current_grouped_3 = range_current7_3.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_3 = range_prev7_3.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_3['curr7_case_3day'] = current_grouped_3['case_diff']\n",
    "current_grouped_3['curr7_death_3day'] = current_grouped_3['death_diff']\n",
    "previous_grouped_3['prev7_case_3day'] = previous_grouped_3['case_diff']\n",
    "previous_grouped_3['prev7_death_3day'] = previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "current_grouped_7 = range_current7_7.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_7 = range_prev7_7.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_7['curr7_case_7day'] = current_grouped_7['case_diff']\n",
    "current_grouped_7['curr7_death_7day'] = current_grouped_7['death_diff']\n",
    "previous_grouped_7['prev7_case_7day'] = previous_grouped_7['case_diff']\n",
    "previous_grouped_7['prev7_death_7day'] = previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "current_grouped_14 = range_current7_14.groupby(['fips'],as_index=False).mean()\n",
    "previous_grouped_14 = range_prev7_14.groupby(['fips'], as_index=False).mean()\n",
    "\n",
    "current_grouped_14['curr7_case_14day'] = current_grouped_14['case_diff']\n",
    "current_grouped_14['curr7_death_14day'] = current_grouped_14['death_diff']\n",
    "previous_grouped_14['prev7_case_14day'] = previous_grouped_14['case_diff']\n",
    "previous_grouped_14['prev7_death_14day'] = previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  state_pop  \\\n",
      "0                  0    0             0                  0  ...   20100000   \n",
      "1                  0    0             0                  2  ...   39937489   \n",
      "2                965  356           201                146  ...   12659682   \n",
      "3                  0    0             0                  0  ...   29472295   \n",
      "4                  0    0             0                  3  ...    7378494   \n",
      "5                  0    0             0                  0  ...   39937489   \n",
      "6                  0    0             0                  0  ...   39937489   \n",
      "7                388    0            82                 50  ...   21992985   \n",
      "8                  0    0             0                  0  ...   29472295   \n",
      "9                  0    0             0                  0  ...   39937489   \n",
      "\n",
      "  Homeloc_count_CCC   curr7_case curr7_death curr7_case_3day  \\\n",
      "0               673   289.285714    7.142857      275.285714   \n",
      "1                93  2424.571429   47.428571     2624.000000   \n",
      "2              3577   614.714286    6.428571      596.571429   \n",
      "3                 0     1.285714    0.000000        1.714286   \n",
      "4                 9  1477.571429   38.714286     1714.857143   \n",
      "5                23   358.714286    3.000000      410.857143   \n",
      "6                50   461.857143   10.285714      411.428571   \n",
      "7               656  2058.142857   42.714286     2764.714286   \n",
      "8                 0     0.428571   -0.142857        0.857143   \n",
      "9                 0   390.285714    9.428571      442.714286   \n",
      "\n",
      "   curr7_death_3day  curr7_case_7day  curr7_death_7day  curr7_case_14day  \\\n",
      "0          8.571429       308.571429         11.714286        355.142857   \n",
      "1         45.428571      2424.142857         38.857143       3052.285714   \n",
      "2          8.428571       568.142857          9.857143        468.285714   \n",
      "3          0.000000         0.714286          0.000000          0.857143   \n",
      "4         42.285714      1779.714286         46.571429       2107.857143   \n",
      "5          4.571429       497.857143          8.571429        519.000000   \n",
      "6         12.428571       551.000000          9.714286        693.714286   \n",
      "7         38.285714      2970.714286         14.285714       2822.000000   \n",
      "8         -0.285714         2.142857         -0.142857          0.142857   \n",
      "9          8.285714       678.142857         11.857143        575.285714   \n",
      "\n",
      "   curr7_death_14day  \n",
      "0          12.428571  \n",
      "1          37.142857  \n",
      "2           6.714286  \n",
      "3           0.000000  \n",
      "4          51.142857  \n",
      "5           7.285714  \n",
      "6          11.428571  \n",
      "7          21.428571  \n",
      "8           0.142857  \n",
      "9           5.142857  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Current with population\n",
    "current_w_pop_a = pd.merge(pop_df,\n",
    "                 current_grouped[['fips','curr7_case', 'curr7_death']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "current_w_pop_b = pd.merge(current_w_pop_a,\n",
    "                 current_grouped_3[['fips','curr7_case_3day', 'curr7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop_c = pd.merge(current_w_pop_b,\n",
    "                 current_grouped_7[['fips','curr7_case_7day', 'curr7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "current_w_pop = pd.merge(current_w_pop_c,\n",
    "                 current_grouped_14[['fips','curr7_case_14day', 'curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(current_w_pop.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  state_pop  \\\n",
      "0                  0    0             0                  0  ...   20100000   \n",
      "1                  0    0             0                  2  ...   39937489   \n",
      "2                965  356           201                146  ...   12659682   \n",
      "3                  0    0             0                  0  ...   29472295   \n",
      "4                  0    0             0                  3  ...    7378494   \n",
      "5                  0    0             0                  0  ...   39937489   \n",
      "6                  0    0             0                  0  ...   39937489   \n",
      "7                388    0            82                 50  ...   21992985   \n",
      "8                  0    0             0                  0  ...   29472295   \n",
      "9                  0    0             0                  0  ...   39937489   \n",
      "\n",
      "  Homeloc_count_CCC   prev7_case prev7_death prev7_case_3day  \\\n",
      "0               673   308.571429   11.714286      345.857143   \n",
      "1                93  2424.142857   38.857143     2754.857143   \n",
      "2              3577   568.142857    9.857143      523.285714   \n",
      "3                 0     0.714286    0.000000        0.571429   \n",
      "4                 9  1779.714286   46.571429     1917.285714   \n",
      "5                23   497.857143    8.571429      512.428571   \n",
      "6                50   551.000000    9.714286      706.000000   \n",
      "7               656  2970.714286   14.285714     2975.428571   \n",
      "8                 0     2.142857   -0.142857        1.428571   \n",
      "9                 0   678.142857   11.857143      696.285714   \n",
      "\n",
      "   prev7_death_3day  prev7_case_7day  prev7_death_7day  prev7_case_14day  \\\n",
      "0         12.571429       355.142857         12.428571        305.285714   \n",
      "1         38.142857      3052.285714         37.142857       2824.000000   \n",
      "2          7.857143       468.285714          6.714286        447.571429   \n",
      "3          0.000000         0.857143          0.000000          1.000000   \n",
      "4         49.857143      2107.857143         51.142857       2384.285714   \n",
      "5          7.857143       519.000000          7.285714        472.714286   \n",
      "6          9.714286       693.714286         11.428571        850.428571   \n",
      "7         15.000000      2822.000000         21.428571       2677.857143   \n",
      "8          0.142857         0.142857          0.142857          1.000000   \n",
      "9          7.142857       575.285714          5.142857        664.428571   \n",
      "\n",
      "   prev7_death_14day  \n",
      "0          16.857143  \n",
      "1          45.000000  \n",
      "2          12.857143  \n",
      "3           0.000000  \n",
      "4          37.857143  \n",
      "5           5.285714  \n",
      "6           9.571429  \n",
      "7          16.857143  \n",
      "8           0.142857  \n",
      "9           6.714286  \n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge both Previous with population\n",
    "\n",
    "previous_w_pop_a = pd.merge(pop_df,\n",
    "                 previous_grouped[['fips','prev7_case', 'prev7_death']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_b = pd.merge(previous_w_pop_a,\n",
    "                 previous_grouped_3[['fips','prev7_case_3day', 'prev7_death_3day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop_c = pd.merge(previous_w_pop_b,\n",
    "                 previous_grouped_7[['fips','prev7_case_7day', 'prev7_death_7day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "previous_w_pop = pd.merge(previous_w_pop_c,\n",
    "                 previous_grouped_14[['fips','prev7_case_14day', 'prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')\n",
    "\n",
    "print(previous_w_pop.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_w_pop['cur_7rollavg_cases'] = ((current_w_pop['curr7_case']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths'] = ((current_w_pop['curr7_death']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#3 day#\n",
    "current_w_pop['cur_7rollavg_cases_3day'] = ((current_w_pop['curr7_case_3day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_3day'] = ((current_w_pop['curr7_death_3day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "current_w_pop['cur_7rollavg_cases_7day'] = ((current_w_pop['curr7_case_7day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_7day'] = ((current_w_pop['curr7_death_7day']/current_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "current_w_pop['cur_7rollavg_cases_14day'] = ((current_w_pop['curr7_case_14day']/current_w_pop['pop'])*100000)\n",
    "current_w_pop['cur_7rollavg_deaths_14day'] = ((current_w_pop['curr7_death_14day']/current_w_pop['pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_w_pop['prev_7rollavg_cases'] = ((previous_w_pop['prev7_case']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths'] = ((previous_w_pop['prev7_death']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#3day#\n",
    "previous_w_pop['prev_7rollavg_cases_3day'] = ((previous_w_pop['prev7_case_3day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_3day'] = ((previous_w_pop['prev7_death_3day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#7 day#\n",
    "previous_w_pop['prev_7rollavg_cases_7day'] = ((previous_w_pop['prev7_case_7day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_7day'] = ((previous_w_pop['prev7_death_7day']/previous_w_pop['pop'])*100000)\n",
    "\n",
    "#14 day#\n",
    "previous_w_pop['prev_7rollavg_cases_14day'] = ((previous_w_pop['prev7_case_14day']/previous_w_pop['pop'])*100000)\n",
    "previous_w_pop['prev_7rollavg_deaths_14day'] = ((previous_w_pop['prev7_death_14day']/previous_w_pop['pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with prevalence dataset\n",
    "prev_curr = pd.merge(prevalence_w_pop,\n",
    "                 current_w_pop[['fips','cur_7rollavg_cases', 'cur_7rollavg_deaths','curr7_case','curr7_death',\n",
    "                               'cur_7rollavg_cases_3day', 'cur_7rollavg_deaths_3day','curr7_case_3day','curr7_death_3day',\n",
    "                               'cur_7rollavg_cases_7day', 'cur_7rollavg_deaths_7day','curr7_case_7day','curr7_death_7day',\n",
    "                                'cur_7rollavg_cases_14day', 'cur_7rollavg_deaths_14day','curr7_case_14day','curr7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_set = pd.merge(prev_curr,\n",
    "                 previous_w_pop[['fips','prev_7rollavg_cases', 'prev_7rollavg_deaths','prev7_case','prev7_death',\n",
    "                                'prev_7rollavg_cases_3day', 'prev_7rollavg_deaths_3day','prev7_case_3day','prev7_death_3day',\n",
    "                               'prev_7rollavg_cases_7day', 'prev_7rollavg_deaths_7day','prev7_case_7day','prev7_death_7day',\n",
    "                                'prev_7rollavg_cases_14day', 'prev_7rollavg_deaths_14day','prev7_case_14day','prev7_death_14day']],\n",
    "                 on='fips', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "\n",
      "   prev7_case_14day prev7_death_14day roll7case_diff roll7death_diff  \\\n",
      "0        305.285714         16.857143      -0.062500       -0.390244   \n",
      "1       2824.000000         45.000000       0.000177        0.220588   \n",
      "2        447.571429         12.857143       0.081971       -0.347826   \n",
      "3          1.000000          0.000000       0.800000             NaN   \n",
      "4       2384.285714         37.857143      -0.169770       -0.168712   \n",
      "\n",
      "  roll7case_diff_3day  roll7death_diff_3day  roll7case_diff_7day  \\\n",
      "0           -0.204048             -0.318182            -0.131134   \n",
      "1           -0.047501              0.191011            -0.205794   \n",
      "2            0.140049              0.072727             0.213240   \n",
      "3            2.000000                   NaN            -0.166667   \n",
      "4           -0.105581             -0.151862            -0.155676   \n",
      "\n",
      "   roll7death_diff_7day  roll7case_diff_14day  roll7death_diff_14day  \n",
      "0             -0.057471              0.163313              -0.262712  \n",
      "1              0.046154              0.080838              -0.174603  \n",
      "2              0.468085              0.046282              -0.477778  \n",
      "3                   NaN             -0.142857                    NaN  \n",
      "4             -0.089385             -0.115938               0.350943  \n",
      "\n",
      "[5 rows x 66 columns]\n"
     ]
    }
   ],
   "source": [
    "#Create indicators for rolling averages\n",
    "county_set['roll7case_diff'] = ((county_set['cur_7rollavg_cases']-county_set['prev_7rollavg_cases'])/county_set['prev_7rollavg_cases'])\n",
    "county_set['roll7death_diff'] = ((county_set['cur_7rollavg_deaths']-county_set['prev_7rollavg_deaths'])/county_set['prev_7rollavg_deaths'])\n",
    "\n",
    "\n",
    "#3 day#\n",
    "county_set['roll7case_diff_3day'] = ((county_set['cur_7rollavg_cases_3day']-county_set['prev_7rollavg_cases_3day'])/county_set['prev_7rollavg_cases_3day'])\n",
    "county_set['roll7death_diff_3day'] = ((county_set['cur_7rollavg_deaths_3day']-county_set['prev_7rollavg_deaths_3day'])/county_set['prev_7rollavg_deaths_3day'])\n",
    "\n",
    "\n",
    "#7day#\n",
    "county_set['roll7case_diff_7day'] = ((county_set['cur_7rollavg_cases_7day']-county_set['prev_7rollavg_cases_7day'])/county_set['prev_7rollavg_cases_7day'])\n",
    "county_set['roll7death_diff_7day'] = ((county_set['cur_7rollavg_deaths_7day']-county_set['prev_7rollavg_deaths_7day'])/county_set['prev_7rollavg_deaths_7day'])\n",
    "\n",
    "\n",
    "#14 day#\n",
    "county_set['roll7case_diff_14day'] = ((county_set['cur_7rollavg_cases_14day']-county_set['prev_7rollavg_cases_14day'])/county_set['prev_7rollavg_cases_14day'])\n",
    "county_set['roll7death_diff_14day'] = ((county_set['cur_7rollavg_deaths_14day']-county_set['prev_7rollavg_deaths_14day'])/county_set['prev_7rollavg_deaths_14day'])\n",
    "\n",
    "print(county_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in NYTimes state data, diff, do same 7 day rolling avg counts\n",
    "# pull in COVID tracking test data. calculate pos % then rolling avgs\n",
    "# Manually pull in Rt, might drop this metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring in state level NYT Data\n",
    "nytimes_state = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\"\n",
    "state= pd.read_csv(nytimes_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    state  fips  cases  deaths    State\n",
      "586  2020-03-13  Alabama     1      6       0  Alabama\n",
      "637  2020-03-14  Alabama     1     12       0  Alabama\n",
      "689  2020-03-15  Alabama     1     23       0  Alabama\n",
      "742  2020-03-16  Alabama     1     29       0  Alabama\n",
      "795  2020-03-17  Alabama     1     39       0  Alabama\n"
     ]
    }
   ],
   "source": [
    "#Create new cases field\n",
    "#Sort df by Fips and Date\n",
    "state['State'] = state['state']\n",
    "state.sort_values(by=['fips','date'],inplace=True, ascending=True)\n",
    "print(state.head())\n",
    "\n",
    "#Take difference between rows for new case and new death numbers\n",
    "state['case_diff'] = state.cases.diff()\n",
    "state['death_diff'] = state.deaths.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CREATE State Prevalence measure\n",
    "#Filter for past 14 days\n",
    "\n",
    "state_range_14 = state[(state['date']>=preval_start) & (state['date']<=preval_end)]\n",
    "\n",
    "#3 day#\n",
    "range_14_3 = state[(state['date']>=preval_start_3) & (state['date']<=preval_end_3)]\n",
    "\n",
    "#7 day#\n",
    "range_14_7 = state[(state['date']>=preval_start_7) & (state['date']<=preval_end_7)]\n",
    "\n",
    "#14 day#\n",
    "range_14_14 = state[(state['date']>=preval_start_14) & (state['date']<=preval_end_14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create state group for prevalence\n",
    "\n",
    "state_prevalence_grouped = state_range_14.groupby(['State'], as_index=False).sum()\n",
    "\n",
    "state_prevalence_grouped['state_active'] = state_prevalence_grouped['case_diff']\n",
    "\n",
    "\n",
    "#3 day#\n",
    "state_prevalence_grouped_3 = range_14_3.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_3[\"state_active_3\"] = prevalence_grouped_3[\"case_diff\"]\n",
    "\n",
    "#7 day#\n",
    "state_prevalence_grouped_7 = range_14_7.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_7[\"state_active_7\"] = prevalence_grouped_7[\"case_diff\"]\n",
    "\n",
    "#14 day#\n",
    "state_prevalence_grouped_14 = range_14_14.groupby(['State'], as_index=False).sum()\n",
    "state_prevalence_grouped_14[\"state_active_14\"] = prevalence_grouped_14[\"case_diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take Current and previous rolling averages\n",
    "\n",
    "state_range_current7 = state[(state['date']>=curr_start) & (state['date']<=curr_end)]\n",
    "state_range_prev7 = state[(state['date']>=prev_start) & (state['date']<=prev_end)]\n",
    "\n",
    "#3 day look back#\n",
    "state_range_current7_3 = state[(state['date']>=curr_start_3) & (state['date']<=curr_end_3)]\n",
    "state_range_prev7_3 = state[(state['date']>=prev_start_3) & (state['date']<=prev_end_3)]\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_range_current7_7 = state[(state['date']>=curr_start_7) & (state['date']<=curr_end_7)]\n",
    "state_range_prev7_7 = state[(state['date']>=prev_start_7) & (state['date']<=prev_end_7)]\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_range_current7_14 = state[(state['date']>=curr_start_14) & (state['date']<=curr_end_14)]\n",
    "state_range_prev7_14 = state[(state['date']>=prev_start_14) & (state['date']<=prev_end_14)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Means\n",
    "#Group by with mean\n",
    "state_current_grouped = state_range_current7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped = state_range_prev7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped['state_curr7_case'] = state_current_grouped['case_diff']\n",
    "state_previous_grouped['state_prev7_case'] = state_previous_grouped['case_diff']\n",
    "state_current_grouped['state_curr7_death'] = state_current_grouped['death_diff']\n",
    "state_previous_grouped['state_prev7_death'] = state_previous_grouped['death_diff']\n",
    "\n",
    "\n",
    "\n",
    "#3 day look back#\n",
    "state_current_grouped_3 = state_range_current7_3.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_3 = state_range_prev7_3.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_3['state_curr7_case_3day'] = state_current_grouped_3['case_diff']\n",
    "state_current_grouped_3['state_curr7_death_3day'] = state_current_grouped_3['death_diff']\n",
    "state_previous_grouped_3['state_prev7_case_3day'] = state_previous_grouped_3['case_diff']\n",
    "state_previous_grouped_3['state_prev7_death_3day'] = state_previous_grouped_3['death_diff']\n",
    "\n",
    "\n",
    "#7 day look back#\n",
    "state_current_grouped_7 = state_range_current7_7.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_7 = state_range_prev7_7.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_7['state_curr7_case_7day'] = state_current_grouped_7['case_diff']\n",
    "state_current_grouped_7['state_curr7_death_7day'] = state_current_grouped_7['death_diff']\n",
    "state_previous_grouped_7['state_prev7_case_7day'] = state_previous_grouped_7['case_diff']\n",
    "state_previous_grouped_7['state_prev7_death_7day'] = state_previous_grouped_7['death_diff']\n",
    "\n",
    "\n",
    "#14 day look back#\n",
    "state_current_grouped_14 = state_range_current7_14.groupby(['State'],as_index=False).mean()\n",
    "state_previous_grouped_14 = state_range_prev7_14.groupby(['State'], as_index=False).mean()\n",
    "\n",
    "state_current_grouped_14['state_curr7_case_14day'] = state_current_grouped_14['case_diff']\n",
    "state_current_grouped_14['state_curr7_death_14day'] = state_current_grouped_14['death_diff']\n",
    "state_previous_grouped_14['state_prev7_case_14day'] = state_previous_grouped_14['case_diff']\n",
    "state_previous_grouped_14['state_prev7_death_14day'] = state_previous_grouped_14['death_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "5                  0    0             0                  0  ...   \n",
      "6                  0    0             0                  0  ...   \n",
      "7                388    0            82                 50  ...   \n",
      "8                  0    0             0                  0  ...   \n",
      "9                  0    0             0                  0  ...   \n",
      "\n",
      "   roll7case_diff_3day roll7death_diff_3day roll7case_diff_7day  \\\n",
      "0            -0.204048            -0.318182           -0.131134   \n",
      "1            -0.047501             0.191011           -0.205794   \n",
      "2             0.140049             0.072727            0.213240   \n",
      "3             2.000000                  NaN           -0.166667   \n",
      "4            -0.105581            -0.151862           -0.155676   \n",
      "5            -0.198216            -0.418182           -0.040738   \n",
      "6            -0.417240             0.279412           -0.205725   \n",
      "7            -0.070818             1.552381            0.052698   \n",
      "8            -0.400000            -3.000000           14.000000   \n",
      "9            -0.364177             0.160000            0.178793   \n",
      "\n",
      "  roll7death_diff_7day roll7case_diff_14day  roll7death_diff_14day  \\\n",
      "0            -0.057471             0.163313              -0.262712   \n",
      "1             0.046154             0.080838              -0.174603   \n",
      "2             0.468085             0.046282              -0.477778   \n",
      "3                  NaN            -0.142857                    NaN   \n",
      "4            -0.089385            -0.115938               0.350943   \n",
      "5             0.176471             0.097915               0.378378   \n",
      "6            -0.150000            -0.184277               0.194030   \n",
      "7            -0.333333             0.053828               0.271186   \n",
      "8            -2.000000            -0.857143               0.000000   \n",
      "9             1.305556            -0.134165              -0.234043   \n",
      "\n",
      "   state_active  state_active_3  state_active_7  state_active_14  \n",
      "0        9407.0            65.0            72.0             64.0  \n",
      "1      116892.0           334.0           309.0            269.0  \n",
      "2       21064.0            41.0            52.0             41.0  \n",
      "3      115833.0           142.0           173.0            207.0  \n",
      "4       31807.0           119.0           147.0            154.0  \n",
      "5      116892.0           334.0           309.0            269.0  \n",
      "6      116892.0           334.0           309.0            269.0  \n",
      "7      127496.0            78.0            81.0             76.0  \n",
      "8      115833.0           142.0           173.0            207.0  \n",
      "9      116892.0           334.0           309.0            269.0  \n",
      "\n",
      "[10 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge PREVALENCE sets with base file\n",
    "\n",
    "state_active_a= pd.merge(county_set,\n",
    "                 state_prevalence_grouped[['State','state_active']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_b = pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "state_active_c = pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active = pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(state_active.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "5  06073      San Diego  California         CA      NaN    347   \n",
      "6  06059         Orange  California         CA      NaN    300   \n",
      "7  12086     Miami-Dade     Florida         FL      NaN   1360   \n",
      "8  48107         Crosby       Texas         TX      NaN      0   \n",
      "9  06065      Riverside  California         CA      NaN     91   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "5                  0    0             0                  0  ...   \n",
      "6                  0    0             0                  0  ...   \n",
      "7                388    0            82                 50  ...   \n",
      "8                  0    0             0                  0  ...   \n",
      "9                  0    0             0                  0  ...   \n",
      "\n",
      "   state_curr7_case_14day state_curr7_death_14day state_prev7_case  \\\n",
      "0              716.285714               18.000000       671.714286   \n",
      "1             9110.428571               93.714286      9226.428571   \n",
      "2             1211.285714               13.714286      1436.285714   \n",
      "3            10136.571429              124.285714      8179.285714   \n",
      "4             2943.428571               82.428571      2466.285714   \n",
      "5             9110.428571               93.714286      9226.428571   \n",
      "6             9110.428571               93.714286      9226.428571   \n",
      "7            11172.142857              113.857143     10306.142857   \n",
      "8            10136.571429              124.285714      8179.285714   \n",
      "9             9110.428571               93.714286      9226.428571   \n",
      "\n",
      "  state_prev7_death state_prev7_case_3day  state_prev7_death_3day  \\\n",
      "0         16.428571            700.714286               18.285714   \n",
      "1        119.000000          10019.000000              104.428571   \n",
      "2         17.714286           1338.571429               15.285714   \n",
      "3        314.142857           8792.857143              147.142857   \n",
      "4         72.285714           2674.571429               79.285714   \n",
      "5        119.000000          10019.000000              104.428571   \n",
      "6        119.000000          10019.000000              104.428571   \n",
      "7        130.142857          10991.714286              126.000000   \n",
      "8        314.142857           8792.857143              147.142857   \n",
      "9        119.000000          10019.000000              104.428571   \n",
      "\n",
      "   state_prev7_case_7day  state_prev7_death_7day  state_prev7_case_14day  \\\n",
      "0             716.285714               18.000000              706.714286   \n",
      "1            9110.428571               93.714286             8403.857143   \n",
      "2            1211.285714               13.714286              992.142857   \n",
      "3           10136.571429              124.285714             9353.428571   \n",
      "4            2943.428571               82.428571             3281.000000   \n",
      "5            9110.428571               93.714286             8403.857143   \n",
      "6            9110.428571               93.714286             8403.857143   \n",
      "7           11172.142857              113.857143            11119.285714   \n",
      "8           10136.571429              124.285714             9353.428571   \n",
      "9            9110.428571               93.714286             8403.857143   \n",
      "\n",
      "   state_prev7_death_14day  \n",
      "0                22.571429  \n",
      "1                94.857143  \n",
      "2                20.571429  \n",
      "3                90.428571  \n",
      "4                58.285714  \n",
      "5                94.857143  \n",
      "6                94.857143  \n",
      "7                81.142857  \n",
      "8                90.428571  \n",
      "9                94.857143  \n",
      "\n",
      "[10 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge CURR sets with base file\n",
    "\n",
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day','state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day','state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day', 'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "\n",
    "\n",
    "# print(state_current_w_pop.head(10))\n",
    "\n",
    "\n",
    "county_state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_b = pd.merge(county_state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df_c = pd.merge(county_state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "county_state_df = pd.merge(county_state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "print(county_state_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create state rolling avg indicator\n",
    "#####NEED TO ADD IN STATE POP to create per 100k \n",
    "\n",
    "county_state_df['state_curr7_case100k'] = ((county_state_df['state_curr7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k'] = ((county_state_df['state_curr7_death']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k'] = ((county_state_df['state_prev7_case']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k'] = ((county_state_df['state_prev7_death']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_curr7_case100k_3day'] = ((county_state_df['state_curr7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_3day'] = ((county_state_df['state_curr7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_3day'] = ((county_state_df['state_prev7_case_3day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_3day'] = ((county_state_df['state_prev7_death_3day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_7day'] = ((county_state_df['state_curr7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_7day'] = ((county_state_df['state_curr7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_7day'] = ((county_state_df['state_prev7_case_7day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_7day'] = ((county_state_df['state_prev7_death_7day']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "county_state_df['state_curr7_case100k_14day'] = ((county_state_df['state_curr7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_curr7_death100k_14day'] = ((county_state_df['state_curr7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_case100k_14day'] = ((county_state_df['state_prev7_case_14day']/county_state_df['state_pop'])*100000)\n",
    "county_state_df['state_prev7_death100k_14day'] = ((county_state_df['state_prev7_death_14day']/county_state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_state_df['state_roll7case_diff'] = ((county_state_df['state_curr7_case100k']-county_state_df['state_prev7_case100k'])/county_state_df['state_prev7_case100k'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_3day'] = ((county_state_df['state_curr7_case100k_3day']-county_state_df['state_prev7_case100k_3day'])/county_state_df['state_prev7_case100k_3day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_7day'] = ((county_state_df['state_curr7_case100k_7day']-county_state_df['state_prev7_case100k_7day'])/county_state_df['state_prev7_case100k_7day'])\n",
    "\n",
    "county_state_df['state_roll7case_diff_14day'] = ((county_state_df['state_curr7_case100k_14day']-county_state_df['state_prev7_case100k_14day'])/county_state_df['state_prev7_case100k_14day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "\n",
      "   state_roll7case_diff_7day state_roll7case_diff_14day state_roll7death_diff  \\\n",
      "0                  -0.062226                   0.013544             -0.226087   \n",
      "1                   0.012733                   0.084077              0.176471   \n",
      "2                   0.185753                   0.220878             -0.177419   \n",
      "3                  -0.193091                   0.083728             -0.349704   \n",
      "4                  -0.162104                  -0.102887             -0.158103   \n",
      "\n",
      "  state_prevalence_per100k state_roll7death_diff_3day  \\\n",
      "0                46.800995                  -0.257813   \n",
      "1               292.687405                   0.281806   \n",
      "2               166.386486                   0.065421   \n",
      "3               393.023346                   1.402913   \n",
      "4               431.077128                  -0.162162   \n",
      "\n",
      "   state_prevalence_per100k_3day  state_roll7death_diff_7day  \\\n",
      "0                       0.323383                   -0.087302   \n",
      "1                       0.836307                    0.269817   \n",
      "2                       0.323863                    0.291667   \n",
      "3                       0.481808                    1.527586   \n",
      "4                       1.612795                   -0.123050   \n",
      "\n",
      "   state_prevalence_per100k_7day  state_roll7death_diff_14day  \\\n",
      "0                       0.358209                    -0.202532   \n",
      "1                       0.773709                    -0.012048   \n",
      "2                       0.410753                    -0.333333   \n",
      "3                       0.586992                     0.374408   \n",
      "4                       1.992276                     0.414216   \n",
      "\n",
      "   state_prevalence_per100k_14day  \n",
      "0                        0.318408  \n",
      "1                        0.673553  \n",
      "2                        0.323863  \n",
      "3                        0.702355  \n",
      "4                        2.087147  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "county_state_df['state_roll7death_diff'] = ((county_state_df['state_curr7_death100k']-county_state_df['state_prev7_death100k'])/county_state_df['state_prev7_death100k'])\n",
    "county_state_df['state_prevalence_per100k'] = ((county_state_df['state_active']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_3day'] = ((county_state_df['state_curr7_death100k_3day']-county_state_df['state_prev7_death100k_3day'])/county_state_df['state_prev7_death100k_3day'])\n",
    "county_state_df['state_prevalence_per100k_3day'] = ((county_state_df['state_active_3']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_7day'] = ((county_state_df['state_curr7_death100k_7day']-county_state_df['state_prev7_death100k_7day'])/county_state_df['state_prev7_death100k_7day'])\n",
    "county_state_df['state_prevalence_per100k_7day'] = ((county_state_df['state_active_7']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "county_state_df['state_roll7death_diff_14day'] = ((county_state_df['state_curr7_death100k_14day']-county_state_df['state_prev7_death100k_14day'])/county_state_df['state_prev7_death100k_14day'])\n",
    "county_state_df['state_prevalence_per100k_14day'] = ((county_state_df['state_active_14']/county_state_df['state_pop'])*100000)\n",
    "\n",
    "print(county_state_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID TRACKING PROJ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#########################################\n",
    "#Bring in COVID TRACKING data\n",
    "url_all = \"https://covidtracking.com/api/v1/states/daily.csv\"\n",
    "testing_all = pd.read_csv(url_all)\n",
    "testing = testing_all[['date','state','positiveIncrease','negativeIncrease', 'totalTestResultsIncrease']]\n",
    "testing['state_code'] = testing['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date state  positiveIncrease  negativeIncrease  \\\n",
      "0  20200804    AK                61              6781   \n",
      "1  20200804    AL              1041              7209   \n",
      "2  20200804    AR               784              5715   \n",
      "3  20200804    AS                 0                 0   \n",
      "4  20200804    AZ              1008              5818   \n",
      "5  20200804    CA              4526            116491   \n",
      "6  20200804    CO               252              4539   \n",
      "7  20200804    CT                48              7041   \n",
      "8  20200804    DC                85              1227   \n",
      "9  20200804    DE                82              1567   \n",
      "\n",
      "   totalTestResultsIncrease state_code  \n",
      "0                      6842         AK  \n",
      "1                      8250         AL  \n",
      "2                      6499         AR  \n",
      "3                         0         AS  \n",
      "4                      6826         AZ  \n",
      "5                    121017         CA  \n",
      "6                      4791         CO  \n",
      "7                      7089         CT  \n",
      "8                      1312         DC  \n",
      "9                      1649         DE  \n"
     ]
    }
   ],
   "source": [
    "print(testing.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "curr_testing = testing[(testing['date']>=curr_test_end) & (testing['date']<=curr_test_start)]\n",
    "curr_testing['curr_pos_%'] = (curr_testing['positiveIncrease']/curr_testing['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing = testing[(testing['date']>=prev_test_end) & (testing['date']<=prev_test_start)]\n",
    "prev_testing['prev_pos_%'] = (prev_testing['positiveIncrease']/prev_testing['totalTestResultsIncrease'])\n",
    "\n",
    "#3day#\n",
    "curr_testing_3 = testing[(testing['date']>=curr_test_end_3) & (testing['date']<=curr_test_start_3)]\n",
    "curr_testing_3['curr_pos_%_3'] = (curr_testing_3['positiveIncrease']/curr_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_3 = testing[(testing['date']>=prev_test_end_3) & (testing['date']<=prev_test_start_3)]\n",
    "prev_testing_3['prev_pos_%_3'] = (prev_testing_3['positiveIncrease']/prev_testing_3['totalTestResultsIncrease'])\n",
    "\n",
    "#7day#\n",
    "curr_testing_7 = testing[(testing['date']>=curr_test_end_7) & (testing['date']<=curr_test_start_7)]\n",
    "curr_testing_7['curr_pos_%_7'] = (curr_testing_7['positiveIncrease']/curr_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_7 = testing[(testing['date']>=prev_test_end_7) & (testing['date']<=prev_test_start_7)]\n",
    "prev_testing_7['prev_pos_%_7'] = (prev_testing_7['positiveIncrease']/prev_testing_7['totalTestResultsIncrease'])\n",
    "\n",
    "#14day#\n",
    "curr_testing_14 = testing[(testing['date']>=curr_test_end_14) & (testing['date']<=curr_test_start_14)]\n",
    "curr_testing_14['curr_pos_%_14'] = (curr_testing_14['positiveIncrease']/curr_testing_14['totalTestResultsIncrease'])\n",
    "\n",
    "prev_testing_14 = testing[(testing['date']>=prev_test_end_14) & (testing['date']<=prev_test_start_14)]\n",
    "prev_testing_14['prev_pos_%_14'] = (prev_testing_14['positiveIncrease']/prev_testing_14['totalTestResultsIncrease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Group by with mean\n",
    "curr_test_grouped = curr_testing.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped = prev_testing.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#3day#\n",
    "curr_test_grouped_3 = curr_testing_3.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_3 = prev_testing_3.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#7day#\n",
    "curr_test_grouped_7 = curr_testing_7.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_7 = prev_testing_7.groupby(['state_code'], as_index=False).mean()\n",
    "\n",
    "#14day#\n",
    "curr_test_grouped_14 = curr_testing_14.groupby(['state_code'],as_index=False).mean()\n",
    "prev_test_grouped_14 = prev_testing_14.groupby(['state_code'], as_index=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "\n",
      "   state_roll7death_diff_3day state_prevalence_per100k_3day  \\\n",
      "0                   -0.257813                      0.323383   \n",
      "1                    0.281806                      0.836307   \n",
      "2                    0.065421                      0.323863   \n",
      "3                    1.402913                      0.481808   \n",
      "4                   -0.162162                      1.612795   \n",
      "\n",
      "  state_roll7death_diff_7day state_prevalence_per100k_7day  \\\n",
      "0                  -0.087302                      0.358209   \n",
      "1                   0.269817                      0.773709   \n",
      "2                   0.291667                      0.410753   \n",
      "3                   1.527586                      0.586992   \n",
      "4                  -0.123050                      1.992276   \n",
      "\n",
      "  state_roll7death_diff_14day  state_prevalence_per100k_14day  curr_pos_%  \\\n",
      "0                   -0.202532                        0.318408    0.010075   \n",
      "1                   -0.012048                        0.673553    0.063457   \n",
      "2                   -0.333333                        0.323863    0.039751   \n",
      "3                    0.374408                        0.702355    0.142403   \n",
      "4                    0.414216                        2.087147    0.179803   \n",
      "\n",
      "   curr_pos_%_3  curr_pos_%_7  curr_pos_%_14  \n",
      "0      0.010061      0.010331       0.011238  \n",
      "1      0.068465      0.074982       0.074754  \n",
      "2      0.039493      0.038650       0.030957  \n",
      "3      0.125166      0.123960       0.154742  \n",
      "4      0.190028      0.218114       0.248501  \n",
      "\n",
      "[5 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "#Merge to County Set\n",
    "\n",
    "curr_merge_a = pd.merge(county_state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(curr_merge.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  \\\n",
      "0                  0    0             0                  0  ...   \n",
      "1                  0    0             0                  2  ...   \n",
      "2                965  356           201                146  ...   \n",
      "3                  0    0             0                  0  ...   \n",
      "4                  0    0             0                  3  ...   \n",
      "\n",
      "   state_roll7death_diff_14day state_prevalence_per100k_14day curr_pos_%  \\\n",
      "0                    -0.202532                       0.318408   0.010075   \n",
      "1                    -0.012048                       0.673553   0.063457   \n",
      "2                    -0.333333                       0.323863   0.039751   \n",
      "3                     0.374408                       0.702355   0.142403   \n",
      "4                     0.414216                       2.087147   0.179803   \n",
      "\n",
      "  curr_pos_%_3 curr_pos_%_7  curr_pos_%_14  prev_pos_%  prev_pos_%_3  \\\n",
      "0     0.010061     0.010331       0.011238    0.010331      0.010957   \n",
      "1     0.068465     0.074982       0.074754    0.074982      0.080050   \n",
      "2     0.039493     0.038650       0.030957    0.038650      0.035804   \n",
      "3     0.125166     0.123960       0.154742    0.123960      0.130243   \n",
      "4     0.190028     0.218114       0.248501    0.218114      0.230437   \n",
      "\n",
      "   prev_pos_%_7  prev_pos_%_14  \n",
      "0      0.011238       0.011281  \n",
      "1      0.074754       0.077834  \n",
      "2      0.030957       0.030576  \n",
      "3      0.154742       0.180888  \n",
      "4      0.248501       0.248035  \n",
      "\n",
      "[5 rows x 122 columns]\n"
     ]
    }
   ],
   "source": [
    "mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_b = pd.merge(mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2_c = pd.merge(mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "mam_v2 = pd.merge(mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "print(mam_v2.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_v2['testing_diff'] = (mam_v2['curr_pos_%'] - mam_v2['prev_pos_%'])\n",
    "mam_v2['testing_diff_3'] = (mam_v2['curr_pos_%_3'] - mam_v2['prev_pos_%_3'])\n",
    "mam_v2['testing_diff_7'] = (mam_v2['curr_pos_%_7'] - mam_v2['prev_pos_%_7'])\n",
    "mam_v2['testing_diff_14'] = (mam_v2['curr_pos_%_14'] - mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State state_code  Level 6   NBCU  \\\n",
      "0  36061  New York City    New York         NY      NaN   2931   \n",
      "1  06037    Los Angeles  California         CA      NaN  10184   \n",
      "2  17031           Cook    Illinois         IL      NaN    803   \n",
      "3  48195       Hansford       Texas         TX      NaN      0   \n",
      "4  04013       Maricopa     Arizona         AZ      NaN    280   \n",
      "\n",
      "   Tech Ops EE Count  CAE  Cable Stores  Business Services  ...  curr_pos_%_7  \\\n",
      "0                  0    0             0                  0  ...      0.010331   \n",
      "1                  0    0             0                  2  ...      0.074982   \n",
      "2                965  356           201                146  ...      0.038650   \n",
      "3                  0    0             0                  0  ...      0.123960   \n",
      "4                  0    0             0                  3  ...      0.218114   \n",
      "\n",
      "  curr_pos_%_14 prev_pos_% prev_pos_%_3 prev_pos_%_7  prev_pos_%_14  \\\n",
      "0      0.011238   0.010331     0.010957     0.011238       0.011281   \n",
      "1      0.074754   0.074982     0.080050     0.074754       0.077834   \n",
      "2      0.030957   0.038650     0.035804     0.030957       0.030576   \n",
      "3      0.154742   0.123960     0.130243     0.154742       0.180888   \n",
      "4      0.248501   0.218114     0.230437     0.248501       0.248035   \n",
      "\n",
      "   testing_diff  testing_diff_3  testing_diff_7  testing_diff_14  \n",
      "0     -0.000256       -0.000896       -0.000907        -0.000043  \n",
      "1     -0.011525       -0.011586        0.000228        -0.003079  \n",
      "2      0.001101        0.003689        0.007692         0.000381  \n",
      "3      0.018443       -0.005076       -0.030782        -0.026146  \n",
      "4     -0.038311       -0.040409       -0.030387         0.000466  \n",
      "\n",
      "[5 rows x 126 columns]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "###Filter out any counties with 0 cases for past 14 days##\n",
    "\n",
    "\n",
    "#county_filtered = mam_v2[(mam_v2['active_cases_100k']>=0)]\n",
    "county_filtered = mam_v2\n",
    "print(mam_v2.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updated 7/1\n",
    "\n",
    "def active(n):\n",
    "    if 0<=n<=49.48: score = 0\n",
    "    elif 49.49<=n<=114.05: score = 1\n",
    "    elif 114.06<=n<=100000: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "\n",
    "def roll(n):\n",
    "    if -1<=n<=-0.10: score = 0\n",
    "    elif -0.10<=n<=0.10: score = 1\n",
    "    elif 0.101111<=n<=100: score = 2\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 0.5  \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_hrvd_state(n):\n",
    "    if -10000<=n<0.10: score = 0\n",
    "    elif 0.10<=n<=10000: score = 1 \n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def roll_indicator(n):\n",
    "    if -10000<=n<0.10: score = \"Decreasing or Steady\"\n",
    "    elif 0.10<=n<=10000: score = \"Increasing\"  \n",
    "    else: score = \"Decreasing or Steady\"\n",
    "    return(score)\n",
    "\n",
    "#def test(n):\n",
    "#    if -2<=n<=-.01: score = 0\n",
    "#    elif -.011111<=n<=.01: score = 1\n",
    "#    elif 0.01111 <=n<= 100: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def test7(n):\n",
    "    if -2<=n< 0.03: score = 0\n",
    "    elif 0.03 <=n<.1: score =1\n",
    "    elif 0.1 <=n<0.15: score =2\n",
    "    elif 0.15 <=n<= 1000: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def curr7(n):\n",
    "#    if -2<=n<=4.9999: score = 0\n",
    "#    elif 5 <=n<=9.9999: score =1\n",
    "#    elif 10 <=n<=99999: score =2\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def curr7_hrvd(n):\n",
    "    if -222<=n<= 2: score = 0\n",
    "    elif 2 <n<10: score =1\n",
    "    elif 10 <=n<25: score =2\n",
    "    elif 25 <=n<=99999: score =3\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "def testch(n):\n",
    "    if 0<=n<=0.1: score = 'Decreasing'\n",
    "    elif 1 <=n<= 1.9: score = 'Steady'\n",
    "    else: score = 'Increasing'\n",
    "    return(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_filtered['County_Active_100k_Score'] = county_filtered['active_cases_100k'].apply(active)\n",
    "county_filtered['State_Active_100k_Score'] = county_filtered['state_prevalence_per100k'].apply(active)\n",
    "county_filtered['County_Roll_Score'] = county_filtered['roll7case_diff'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend'] = county_filtered['roll7case_diff'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score'] = county_filtered['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score'] = county_filtered['testing_diff'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg'] = county_filtered['curr_pos_%'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg'] = county_filtered['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg'] = county_filtered['cur_7rollavg_cases'].apply(curr7_hrvd)\n",
    "\n",
    "#3day#\n",
    "county_filtered_3day = county_filtered\n",
    "county_filtered['County_Active_100k_Score_3'] = county_filtered['active_cases_100k_3day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_3'] = county_filtered['state_prevalence_per100k_3day'].apply(active)\n",
    "county_filtered['County_Roll_Score_3'] = county_filtered['roll7case_diff_3day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_3'] = county_filtered['roll7case_diff_3day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_3'] = county_filtered['state_roll7case_diff_3day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_3'] = county_filtered['testing_diff_3'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_3'] = county_filtered['curr_pos_%_3'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_3'] = county_filtered['state_curr7_case100k_3day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_3'] = county_filtered['cur_7rollavg_cases_3day'].apply(curr7_hrvd)\n",
    "\n",
    "#7day#\n",
    "county_filtered['County_Active_100k_Score_7'] = county_filtered['active_cases_100k_7day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_7'] = county_filtered['state_prevalence_per100k_7day'].apply(active)\n",
    "county_filtered['County_Roll_Score_7'] = county_filtered['roll7case_diff_7day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_7'] = county_filtered['roll7case_diff_7day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_7'] = county_filtered['state_roll7case_diff_7day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_7'] = county_filtered['testing_diff_7'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_7'] = county_filtered['curr_pos_%_7'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_7'] = county_filtered['state_curr7_case100k_7day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_7'] = county_filtered['cur_7rollavg_cases_7day'].apply(curr7_hrvd)\n",
    "\n",
    "#14day#\n",
    "county_filtered['County_Active_100k_Score_14'] = county_filtered['active_cases_100k_14day'].apply(active)\n",
    "county_filtered['State_Active_100k_Score_14'] = county_filtered['state_prevalence_per100k_14day'].apply(active)\n",
    "county_filtered['County_Roll_Score_14'] = county_filtered['roll7case_diff_14day'].apply(roll_hrvd)\n",
    "county_filtered['County Case Trend_14'] = county_filtered['roll7case_diff_14day'].apply(roll_indicator)\n",
    "\n",
    "county_filtered['State_Roll_Score_14'] = county_filtered['state_roll7case_diff_14day'].apply(roll_hrvd_state)\n",
    "\n",
    "# county_filtered['State_Testing_Score_14'] = county_filtered['testing_diff_14'].apply(test)\n",
    "county_filtered['State_7Day_Pos_Test_Avg_14'] = county_filtered['curr_pos_%_14'].apply(test7)\n",
    "county_filtered['State_7Day_New_Case_Rolling_Avg_14'] = county_filtered['state_curr7_case100k_14day'].apply(curr7_hrvd)\n",
    "county_filtered['County_7Day_New_Case_Rolling_Avg_14'] = county_filtered['cur_7rollavg_cases_14day'].apply(curr7_hrvd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_filtered['State_Composite_Score'] =  ( county_filtered['State_Roll_Score']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "county_filtered['County_Composite_Score'] = (county_filtered['County_Roll_Score'] + county_filtered['County_7Day_New_Case_Rolling_Avg'])\n",
    "\n",
    "#3day#\n",
    "county_filtered['State_Composite_Score_3'] =  ( county_filtered['State_Roll_Score_3']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "county_filtered['County_Composite_Score_3'] = (county_filtered['County_Roll_Score_3'] + county_filtered['County_7Day_New_Case_Rolling_Avg_3'])\n",
    "\n",
    "\n",
    "# #7 day#\n",
    "county_filtered['State_Composite_Score_7'] =  ( county_filtered['State_Roll_Score_7']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "county_filtered['County_Composite_Score_7'] = (county_filtered['County_Roll_Score_7'] + county_filtered['County_7Day_New_Case_Rolling_Avg_7'])\n",
    "\n",
    "\n",
    "# #14 day#\n",
    "county_filtered['State_Composite_Score_14'] =  ( county_filtered['State_Roll_Score_14']\n",
    "                                             +county_filtered['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +county_filtered['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "county_filtered['County_Composite_Score_14'] = (county_filtered['County_Roll_Score_14'] + county_filtered['County_7Day_New_Case_Rolling_Avg_14'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def county(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 0.1<=n<=1: score = \"Low\"\n",
    "#    elif 1<n<=2: score = \"Moderate\"\n",
    "#    elif 2<n<=3: score = \"Severe\"\n",
    "#    elif 4<=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "def county_hrvd(n):\n",
    "    if 0<=n<0.5: score = \"Minimal\"\n",
    "    elif 0.5<=n<1: score = \"Low\"\n",
    "    elif 1<=n<2: score = \"Moderate\"\n",
    "    elif 2<=n<3: score = \"Elevated\"\n",
    "    elif 3<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "\n",
    "def state(n):\n",
    "    if 0<=n<1: score = \"Minimal\"\n",
    "    elif 1<=n<2: score = \"Low\"\n",
    "    elif 2<=n<4: score = \"Moderate\"\n",
    "    elif 4<=n<6: score = \"Elevated\"\n",
    "    elif 6<=n<= 100: score = \"Critical\"\n",
    "    else: score = 0\n",
    "    return(score)\n",
    "\n",
    "#def blend(n):\n",
    "#    if 0<=n<=.99: score = \"Minimal\"\n",
    "#    elif 1<=n<=2: score = \"Low\"\n",
    "#    elif 3<=n<=4: score = \"Moderate\"\n",
    "#    elif 5<=n<=6: score = \"Severe\"\n",
    "#    elif 7 <=n<= 100: score = \"Extreme\"\n",
    "#    else: score = 0\n",
    "#    return(score)\n",
    "\n",
    "county_filtered['County_Level'] = county_filtered['County_Composite_Score'].apply(county_hrvd)\n",
    "county_filtered['State_Level'] = county_filtered['State_Composite_Score'].apply(state)\n",
    "#county_filtered['County_State_Blend'] = ((county_filtered['County_Composite_Score']+county_filtered['State_Composite_Score']))\n",
    "#county_filtered['County_State_Level'] = county_filtered['County_State_Blend'].apply(blend)\n",
    "\n",
    "#3day, 7 day, 14 day#\n",
    "county_filtered['County_Level_3'] = county_filtered['County_Composite_Score_3'].apply(county_hrvd)\n",
    "county_filtered['State_Level_3'] = county_filtered['State_Composite_Score_3'].apply(state)\n",
    "county_filtered['County_Level_7'] = county_filtered['County_Composite_Score_7'].apply(county_hrvd)\n",
    "county_filtered['State_Level_7'] = county_filtered['State_Composite_Score_7'].apply(state)\n",
    "county_filtered['County_Level_14'] = county_filtered['County_Composite_Score_14'].apply(county_hrvd)\n",
    "county_filtered['State_Level_14'] = county_filtered['State_Composite_Score_14'].apply(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fips         County       State County_Level State_Level  \\\n",
      "0  36061  New York City    New York      Minimal         Low   \n",
      "1  06037    Los Angeles  California     Elevated    Moderate   \n",
      "2  17031           Cook    Illinois     Elevated    Moderate   \n",
      "3  48195       Hansford       Texas     Elevated    Elevated   \n",
      "4  04013       Maricopa     Arizona     Critical    Critical   \n",
      "\n",
      "   County_Composite_Score  cur_7rollavg_cases     County Case Trend  \\\n",
      "0                     0.0            1.538426  Decreasing or Steady   \n",
      "1                     2.0           24.151266  Decreasing or Steady   \n",
      "2                     2.0           11.935660  Decreasing or Steady   \n",
      "3                     2.5           23.813934            Increasing   \n",
      "4                     3.0           32.941696  Decreasing or Steady   \n",
      "\n",
      "  County_Level_3 County_Level_7 County_Level_14  New Cases per 100k_7 dayavg  \\\n",
      "0        Minimal        Minimal             Low                     1.538426   \n",
      "1       Critical       Elevated        Critical                    24.151266   \n",
      "2       Elevated       Elevated        Moderate                    11.935660   \n",
      "3       Critical       Elevated        Elevated                    23.813934   \n",
      "4       Critical       Critical        Critical                    32.941696   \n",
      "\n",
      "  Historical County Composite Score_3Days Back  \\\n",
      "0                                      Minimal   \n",
      "1                                     Critical   \n",
      "2                                     Elevated   \n",
      "3                                     Critical   \n",
      "4                                     Critical   \n",
      "\n",
      "  Historical County Composite Score_7Days Back  \\\n",
      "0                                      Minimal   \n",
      "1                                     Elevated   \n",
      "2                                     Elevated   \n",
      "3                                     Elevated   \n",
      "4                                     Critical   \n",
      "\n",
      "  Historical County Composite Score_14Days Back  \n",
      "0                                           Low  \n",
      "1                                      Critical  \n",
      "2                                      Moderate  \n",
      "3                                      Elevated  \n",
      "4                                      Critical  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "##ADD FIELDS FOR LOOK BACKS HERE\n",
    "\n",
    "county_fields = county_filtered[['fips',\n",
    "    'County','State','County_Level', 'State_Level', 'County_Composite_Score',\n",
    "                                 'cur_7rollavg_cases','County Case Trend',                    \n",
    "#                                  'Total CCC','CAE','Cable Stores','Business Services', 'Tech Ops EE Count',\n",
    "                                'County_Level_3',\n",
    "#                                  'State_Level_3', \n",
    "                                'County_Level_7',\n",
    "#                                  'State_Level_7', \n",
    "                                'County_Level_14'\n",
    "#                                  ,'State_Level_14'\n",
    "                                ]]\n",
    "\n",
    "county_fields['New Cases per 100k_7 dayavg'] = county_fields['cur_7rollavg_cases']\n",
    "county_fields['Historical County Composite Score_3Days Back'] = county_fields['County_Level_3']\n",
    "county_fields['Historical County Composite Score_7Days Back'] = county_fields['County_Level_7']\n",
    "county_fields['Historical County Composite Score_14Days Back'] = county_fields['County_Level_14']\n",
    "\n",
    "print(county_fields.head())\n",
    "county_fields.to_csv(file,index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create State Only File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge state data with state base file \n",
    "\n",
    "state_active_a= pd.merge(state_pop_df,\n",
    "                 state_prevalence_grouped[['State','state_active',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "#3,7,14 day#\n",
    "state_active_b= pd.merge(state_active_a,\n",
    "                 state_prevalence_grouped_3[['State','state_active_3',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active_c= pd.merge(state_active_b,\n",
    "                 state_prevalence_grouped_7[['State','state_active_7',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_active= pd.merge(state_active_c,\n",
    "                 state_prevalence_grouped_14[['State','state_active_14',\n",
    "                                       ]],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_current_w_pop_a = pd.merge(state_active,\n",
    "                 state_current_grouped[['State','state_curr7_case',\n",
    "                                       'state_curr7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "\n",
    "state_current_w_pop_b = pd.merge(state_current_w_pop_a,\n",
    "                 state_current_grouped_3[['State','state_curr7_case_3day',\n",
    "                                       'state_curr7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop_c = pd.merge(state_current_w_pop_b,\n",
    "                 state_current_grouped_7[['State','state_curr7_case_7day',\n",
    "                                       'state_curr7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_current_w_pop = pd.merge(state_current_w_pop_c,\n",
    "                 state_current_grouped_14[['State','state_curr7_case_14day',\n",
    "                                       'state_curr7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_a = pd.merge(state_current_w_pop,\n",
    "                 state_previous_grouped[['State','state_prev7_case','state_prev7_death']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_b = pd.merge(state_df_a,\n",
    "                 state_previous_grouped_3[['State','state_prev7_case_3day','state_prev7_death_3day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df_c = pd.merge(state_df_b,\n",
    "                 state_previous_grouped_7[['State','state_prev7_case_7day','state_prev7_death_7day']],\n",
    "                 on='State', \n",
    "                how='left')\n",
    "state_df = pd.merge(state_df_c,\n",
    "                 state_previous_grouped_14[['State','state_prev7_case_14day','state_prev7_death_14day']],\n",
    "                 on='State', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create State Level metrics\n",
    "\n",
    "state_df['state_curr7_case100k'] = ((state_df['state_curr7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k'] = ((state_df['state_curr7_death']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k'] = ((state_df['state_prev7_case']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k'] = ((state_df['state_prev7_death']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff'] = ((state_df['state_curr7_case100k']-state_df['state_prev7_case100k'])/state_df['state_prev7_case100k'])\n",
    "state_df['state_roll7death_diff'] = ((state_df['state_curr7_death100k']-state_df['state_prev7_death100k'])/state_df['state_prev7_death100k'])\n",
    "state_df['state_prevalence_per100k'] = ((state_df['state_active']/state_df['state_pop'])*100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3day\n",
    "state_df['state_curr7_case100k_3'] = ((state_df['state_curr7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_3'] = ((state_df['state_curr7_death_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_3'] = ((state_df['state_prev7_case_3day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_3'] = ((state_df['state_prev7_death_3day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_3'] = ((state_df['state_curr7_case100k_3']-state_df['state_prev7_case100k_3'])/state_df['state_prev7_case100k_3'])\n",
    "state_df['state_roll7death_diff_3'] = ((state_df['state_curr7_death100k_3']-state_df['state_prev7_death100k_3'])/state_df['state_prev7_death100k_3'])\n",
    "state_df['state_prevalence_per100k_3'] = ((state_df['state_active_3']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "#7day\n",
    "state_df['state_curr7_case100k_7'] = ((state_df['state_curr7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_7'] = ((state_df['state_curr7_death_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_7'] = ((state_df['state_prev7_case_7day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_7'] = ((state_df['state_prev7_death_7day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_7'] = ((state_df['state_curr7_case100k_7']-state_df['state_prev7_case100k_7'])/state_df['state_prev7_case100k_7'])\n",
    "state_df['state_roll7death_diff_7'] = ((state_df['state_curr7_death100k_7']-state_df['state_prev7_death100k_7'])/state_df['state_prev7_death100k_7'])\n",
    "state_df['state_prevalence_per100k_7'] = ((state_df['state_active_7']/state_df['state_pop'])*100000)\n",
    "\n",
    "#14day\n",
    "state_df['state_curr7_case100k_14'] = ((state_df['state_curr7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_curr7_death100k_14'] = ((state_df['state_curr7_death_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_case100k_14'] = ((state_df['state_prev7_case_14day']/state_df['state_pop'])*100000)\n",
    "state_df['state_prev7_death100k_14'] = ((state_df['state_prev7_death_14day']/state_df['state_pop'])*100000)\n",
    "\n",
    "\n",
    "state_df['state_roll7case_diff_14'] = ((state_df['state_curr7_case100k_14']-state_df['state_prev7_case100k_14'])/state_df['state_prev7_case100k_14'])\n",
    "state_df['state_roll7death_diff_14'] = ((state_df['state_curr7_death100k_14']-state_df['state_prev7_death100k_14'])/state_df['state_prev7_death100k_14'])\n",
    "state_df['state_prevalence_per100k_14'] = ((state_df['state_active_14']/state_df['state_pop'])*100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Covid Tracking Data\n",
    "\n",
    "\n",
    "curr_merge_a = pd.merge(state_df,\n",
    "                 curr_test_grouped[['state_code','curr_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_b = pd.merge(curr_merge_a,\n",
    "                 curr_test_grouped_3[['state_code','curr_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n",
    "curr_merge_c = pd.merge(curr_merge_b,\n",
    "                 curr_test_grouped_7[['state_code','curr_pos_%_7']], on='state_code', how='left')\n",
    "\n",
    "curr_merge = pd.merge(curr_merge_c,\n",
    "                 curr_test_grouped_14[['state_code','curr_pos_%_14']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mam_v2_a = pd.merge(curr_merge,\n",
    "                 prev_test_grouped[['state_code','prev_pos_%']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_b = pd.merge(state_mam_v2_a,\n",
    "                 prev_test_grouped_3[['state_code','prev_pos_%_3']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2_c = pd.merge(state_mam_v2_b,\n",
    "                 prev_test_grouped_7[['state_code','prev_pos_%_7']],\n",
    "                 on='state_code', \n",
    "                how='left')\n",
    "state_mam_v2 = pd.merge(state_mam_v2_c,\n",
    "                 prev_test_grouped_14[['state_code','prev_pos_%_14',]],\n",
    "                 on='state_code', \n",
    "                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state_mam_v2['testing_diff'] = (state_mam_v2['curr_pos_%'] - state_mam_v2['prev_pos_%'])\n",
    "state_mam_v2['testing_diff_3'] = (state_mam_v2['curr_pos_%_3'] - state_mam_v2['prev_pos_%_3'])\n",
    "state_mam_v2['testing_diff_7'] = (state_mam_v2['curr_pos_%_7'] - state_mam_v2['prev_pos_%_7'])\n",
    "state_mam_v2['testing_diff_14'] = (state_mam_v2['curr_pos_%_14'] - state_mam_v2['prev_pos_%_14'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State Level Scores\n",
    "\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score'] = state_mam_v2['state_prevalence_per100k'].apply(active)\n",
    "state_mam_v2['State_Roll_Score'] = state_mam_v2['state_roll7case_diff'].apply(roll_hrvd_state)\n",
    "\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg'] = state_mam_v2['curr_pos_%'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg'] = state_mam_v2['state_curr7_case100k'].apply(curr7_hrvd)\n",
    "\n",
    "#3,7,14 day\n",
    "state_mam_v2['State_Active_100k_Score_3'] = state_mam_v2['state_prevalence_per100k_3'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_3'] = state_mam_v2['state_roll7case_diff_3'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_3'] = state_mam_v2['curr_pos_%_3'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_3'] = state_mam_v2['state_curr7_case100k_3'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_7'] = state_mam_v2['state_prevalence_per100k_7'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_7'] = state_mam_v2['state_roll7case_diff_7'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_7'] = state_mam_v2['curr_pos_%_7'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_7'] = state_mam_v2['state_curr7_case100k_7'].apply(curr7_hrvd)\n",
    "\n",
    "state_mam_v2['State_Active_100k_Score_14'] = state_mam_v2['state_prevalence_per100k_14'].apply(active)\n",
    "state_mam_v2['State_Roll_Score_14'] = state_mam_v2['state_roll7case_diff_14'].apply(roll_hrvd_state)\n",
    "#state_mam_v2['State_Fatality_Roll_Score'] = state_mam_v2['state_roll7death_diff'].apply(fatal)\n",
    "#state_mam_v2['State_Testing_Score'] = state_mam_v2['testing_diff'].apply(test)\n",
    "state_mam_v2['State_7Day_Pos_Test_Avg_14'] = state_mam_v2['curr_pos_%_14'].apply(test7)\n",
    "state_mam_v2['State_7Day_New_Case_Rolling_Avg_14'] = state_mam_v2['state_curr7_case100k_14'].apply(curr7_hrvd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final dataset\n",
    "\n",
    "state_mam_v2['State Composite Score'] =  (  state_mam_v2['State_Roll_Score']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg'])\n",
    "\n",
    "state_mam_v2['State Classification'] = state_mam_v2['State Composite Score'].apply(state)\n",
    "#state_mam_v2['Test_Change_Classification'] = state_mam_v2['State_Testing_Score'].apply(testch)\n",
    "\n",
    "\n",
    "#3day\n",
    "state_mam_v2['State Composite Score_3'] =  (  state_mam_v2['State_Roll_Score_3']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_3']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_3'])\n",
    "\n",
    "state_mam_v2['State Classification_3'] = state_mam_v2['State Composite Score_3'].apply(state)\n",
    "\n",
    "#7day\n",
    "state_mam_v2['State Composite Score_7'] =  (  state_mam_v2['State_Roll_Score_7']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_7']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_7'])\n",
    "\n",
    "state_mam_v2['State Classification_7'] = state_mam_v2['State Composite Score_7'].apply(state)\n",
    "\n",
    "#14 day\n",
    "state_mam_v2['State Composite Score_14'] =  (  state_mam_v2['State_Roll_Score_14']\n",
    "                                             + state_mam_v2['State_7Day_New_Case_Rolling_Avg_14']\n",
    "                                             +state_mam_v2['State_7Day_Pos_Test_Avg_14'])\n",
    "\n",
    "state_mam_v2['State Classification_14'] = state_mam_v2['State Composite Score_14'].apply(state)\n",
    "\n",
    "\n",
    "final_state_df = state_mam_v2.query('comcast_state ==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State State Classification  State Composite Score  \\\n",
      "0     Alabama             Critical                      6   \n",
      "2     Arizona             Critical                      6   \n",
      "3    Arkansas             Elevated                      5   \n",
      "4  California             Moderate                      3   \n",
      "5    Colorado             Moderate                      2   \n",
      "\n",
      "   state_curr7_case100k  curr_pos_%  state_roll7case_diff  \\\n",
      "0             32.991518    0.227776             -0.055963   \n",
      "2             28.157120    0.179803             -0.157611   \n",
      "3             24.444139    0.256768             -0.058994   \n",
      "4             18.710311    0.063457             -0.190106   \n",
      "5              7.507573    0.065577             -0.280225   \n",
      "\n",
      "   State_7Day_Pos_Test_Avg  State_7Day_New_Case_Rolling_Avg  \\\n",
      "0                        3                                3   \n",
      "2                        3                                3   \n",
      "3                        3                                2   \n",
      "4                        1                                2   \n",
      "5                        1                                1   \n",
      "\n",
      "  State Classification_3 State Classification_7 State Classification_14  \\\n",
      "0               Critical               Critical                Critical   \n",
      "2               Critical               Critical                Critical   \n",
      "3               Elevated               Critical                Moderate   \n",
      "4               Moderate               Moderate                Moderate   \n",
      "5               Moderate               Elevated                Moderate   \n",
      "\n",
      "   New Cases p 100K_7 day avg  Positive Test %_7 day avg  WOW Case Trend %  \\\n",
      "0                   32.991518                   0.227776         -0.055963   \n",
      "2                   28.157120                   0.179803         -0.157611   \n",
      "3                   24.444139                   0.256768         -0.058994   \n",
      "4                   18.710311                   0.063457         -0.190106   \n",
      "5                    7.507573                   0.065577         -0.280225   \n",
      "\n",
      "  Historical State Composite Score_3Days Back  \\\n",
      "0                                    Critical   \n",
      "2                                    Critical   \n",
      "3                                    Elevated   \n",
      "4                                    Moderate   \n",
      "5                                    Moderate   \n",
      "\n",
      "  Historical State Composite Score_7Days Back  \\\n",
      "0                                    Critical   \n",
      "2                                    Critical   \n",
      "3                                    Critical   \n",
      "4                                    Moderate   \n",
      "5                                    Elevated   \n",
      "\n",
      "  Historical State Composite Score_14Days Back  \n",
      "0                                     Critical  \n",
      "2                                     Critical  \n",
      "3                                     Moderate  \n",
      "4                                     Moderate  \n",
      "5                                     Moderate  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\dherlu494\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#Export State File to CSV\n",
    "\n",
    "final_state_df2 = final_state_df[['State', 'State Classification', 'State Composite Score','state_curr7_case100k','curr_pos_%',\n",
    "                                  'state_roll7case_diff', \n",
    "#                                   'State_Roll_Score',\n",
    "                                 'State_7Day_Pos_Test_Avg','State_7Day_New_Case_Rolling_Avg',\n",
    "#                                  'Comcast Employees','CAE','Cable Stores','Business Services', 'Tech Ops','Warehouse',\n",
    "                                 'State Classification_3',\n",
    "                                 'State Classification_7',\n",
    "                                 'State Classification_14']]\n",
    "\n",
    "final_state_df2['New Cases p 100K_7 day avg'] =  final_state_df2['state_curr7_case100k']\n",
    "final_state_df2['Positive Test %_7 day avg'] =  final_state_df2['curr_pos_%']\n",
    "final_state_df2['WOW Case Trend %'] =  final_state_df2['state_roll7case_diff']\n",
    "final_state_df2['Historical State Composite Score_3Days Back'] =  final_state_df2['State Classification_3']\n",
    "final_state_df2['Historical State Composite Score_7Days Back'] =  final_state_df2['State Classification_7']\n",
    "final_state_df2['Historical State Composite Score_14Days Back'] =  final_state_df2['State Classification_14']\n",
    "\n",
    "print(final_state_df2.head())\n",
    "final_state_df2.to_csv(state_file, index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State state_code  Comcast Employees  state_pop  CAE  Cable Stores  \\\n",
      "0     Alabama         AL                391    4908621   65            36   \n",
      "1      Alaska         AK                  0    3038999    0             0   \n",
      "2     Arizona         AZ                720    7378494  227            17   \n",
      "3    Arkansas         AR                112    3038999    1            10   \n",
      "4  California         CA               4747   39937489   87           471   \n",
      "\n",
      "   Business Services  Tech Ops  Warehouse  comcast_state  NBCU_pop  \n",
      "0                  8       191         10              1         0  \n",
      "1                  0         0          0              0         0  \n",
      "2                  5        86          2              1       335  \n",
      "3                  7        62          4              1        56  \n",
      "4                215      1966         50              1     12431  \n"
     ]
    }
   ],
   "source": [
    "print(state_pop_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
